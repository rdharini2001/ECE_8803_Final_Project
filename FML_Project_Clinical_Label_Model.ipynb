{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES"
      ],
      "metadata": {
        "id": "Gqkwy_UMieJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "data = np.genfromtxt('/content/Biomarker_Clinical_Data_Images.csv', delimiter=',', skip_header=1, usecols=(2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20))\n",
        "\n",
        "avgArr = np.zeros([int(data.shape[0]/49), data.shape[1]])\n",
        "\n",
        "for i in range(0, int(data.shape[0]/49)):\n",
        "  start = 49*i+1\n",
        "  scans = data[start:start+48,:]\n",
        "  avgArr[i] = scans.mean(axis=0)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "presence = np.ceil(avgArr)\n",
        "\n",
        "biomarkerAvg, temp = np.hsplit(avgArr, np.array([16]))\n",
        "__, scores = np.hsplit(temp, np.array([1]))\n",
        "biomarkerPresence, __ = np.hsplit(presence, np.array([16]))\n",
        "\n",
        "avg_train, avg_test, score_train, score_test = train_test_split(biomarkerAvg, scores, train_size = 150, test_size=42, random_state=0)\n",
        "presence_train, presence_test, __, __ = train_test_split(biomarkerPresence, scores, train_size = 150, test_size=42, random_state=0)\n",
        "\n",
        "score_train = (score_train - score_train.min(0))/score_train.ptp(0)\n",
        "score_test = (score_test - score_test.min(0))/score_test.ptp(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "RDZ7l291AiNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_avg_train = Variable(torch.from_numpy(avg_train).float())\n",
        "torch_avg_test = Variable(torch.from_numpy(avg_test).float())\n",
        "torch_presence_train = Variable(torch.from_numpy(presence_train).float())\n",
        "torch_presence_test = Variable(torch.from_numpy(presence_test).float())\n",
        "torch_score_train = Variable(torch.from_numpy(score_train).float())\n",
        "torch_score_test = Variable(torch.from_numpy(score_test).float())\n",
        "\n",
        "class LinearRegressionModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(2, 4)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(4, 16)\n",
        "    def forward(self, x):\n",
        "        X = self.linear(x)\n",
        "        X2 = self.relu(X)\n",
        "        y_pred = self.linear2(X2)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "m8e5z2fUFh6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = LinearRegressionModel()\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "hQUKx984bBWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5000):\n",
        "\n",
        "    # Forward pass: Compute predicted y by passing\n",
        "    # x to the model\n",
        "    pred_y = model(torch_score_train)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = loss_fn(pred_y, torch_presence_train)\n",
        "\n",
        "    # Zero gradients, perform a backward pass,\n",
        "    # and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch % 20 == 0):\n",
        "      print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "test_pred = model(torch_score_test)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "torch.set_printoptions(threshold=10_000)\n",
        "print(test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qipi2VvuNUa-",
        "outputId": "bec2c84a-fb16-4d55-e4a3-cebbf2aba92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 0.11827762424945831\n",
            "epoch 20, loss 0.11827044188976288\n",
            "epoch 40, loss 0.11826324462890625\n",
            "epoch 60, loss 0.11825606971979141\n",
            "epoch 80, loss 0.11824891716241837\n",
            "epoch 100, loss 0.11824175715446472\n",
            "epoch 120, loss 0.11823461204767227\n",
            "epoch 140, loss 0.11822747439146042\n",
            "epoch 160, loss 0.11822034418582916\n",
            "epoch 180, loss 0.1182132363319397\n",
            "epoch 200, loss 0.11820604652166367\n",
            "epoch 220, loss 0.11819882690906525\n",
            "epoch 240, loss 0.11819161474704742\n",
            "epoch 260, loss 0.1181844174861908\n",
            "epoch 280, loss 0.11817722022533417\n",
            "epoch 300, loss 0.11817005276679993\n",
            "epoch 320, loss 0.11816287785768509\n",
            "epoch 340, loss 0.11815571784973145\n",
            "epoch 360, loss 0.11814858764410019\n",
            "epoch 380, loss 0.11814142763614655\n",
            "epoch 400, loss 0.11813430488109589\n",
            "epoch 420, loss 0.11812718957662582\n",
            "epoch 440, loss 0.11812008172273636\n",
            "epoch 460, loss 0.11811298131942749\n",
            "epoch 480, loss 0.11810588836669922\n",
            "epoch 500, loss 0.11809880286455154\n",
            "epoch 520, loss 0.11809173226356506\n",
            "epoch 540, loss 0.11808466911315918\n",
            "epoch 560, loss 0.1180776059627533\n",
            "epoch 580, loss 0.1180705651640892\n",
            "epoch 600, loss 0.1180635318160057\n",
            "epoch 620, loss 0.11805649846792221\n",
            "epoch 640, loss 0.11804948002099991\n",
            "epoch 660, loss 0.1180424913764\n",
            "epoch 680, loss 0.11803548038005829\n",
            "epoch 700, loss 0.11802849173545837\n",
            "epoch 720, loss 0.11802149564027786\n",
            "epoch 740, loss 0.11801452934741974\n",
            "epoch 760, loss 0.11800755560398102\n",
            "epoch 780, loss 0.11800060421228409\n",
            "epoch 800, loss 0.11799364537000656\n",
            "epoch 820, loss 0.11798670142889023\n",
            "epoch 840, loss 0.11797976493835449\n",
            "epoch 860, loss 0.11797284334897995\n",
            "epoch 880, loss 0.117965929210186\n",
            "epoch 900, loss 0.11795900762081146\n",
            "epoch 920, loss 0.11795211583375931\n",
            "epoch 940, loss 0.11794522404670715\n",
            "epoch 960, loss 0.117938332259655\n",
            "epoch 980, loss 0.11793147027492523\n",
            "epoch 1000, loss 0.11792458593845367\n",
            "epoch 1020, loss 0.11791772395372391\n",
            "epoch 1040, loss 0.11791086941957474\n",
            "epoch 1060, loss 0.11790402978658676\n",
            "epoch 1080, loss 0.11789717525243759\n",
            "epoch 1100, loss 0.11789034307003021\n",
            "epoch 1120, loss 0.11788351833820343\n",
            "epoch 1140, loss 0.11787668615579605\n",
            "epoch 1160, loss 0.11786988377571106\n",
            "epoch 1180, loss 0.11786308139562607\n",
            "epoch 1200, loss 0.11785626411437988\n",
            "epoch 1220, loss 0.11784947663545609\n",
            "epoch 1240, loss 0.11784268915653229\n",
            "epoch 1260, loss 0.11783592402935028\n",
            "epoch 1280, loss 0.11782912909984589\n",
            "epoch 1300, loss 0.11782237887382507\n",
            "epoch 1320, loss 0.11781560629606247\n",
            "epoch 1340, loss 0.11780884116888046\n",
            "epoch 1360, loss 0.11780206114053726\n",
            "epoch 1380, loss 0.11779531091451645\n",
            "epoch 1400, loss 0.11778853088617325\n",
            "epoch 1420, loss 0.11778176575899124\n",
            "epoch 1440, loss 0.11777500063180923\n",
            "epoch 1460, loss 0.11776823550462723\n",
            "epoch 1480, loss 0.11776150017976761\n",
            "epoch 1500, loss 0.1177547350525856\n",
            "epoch 1520, loss 0.11774799227714539\n",
            "epoch 1540, loss 0.11774126440286636\n",
            "epoch 1560, loss 0.11773454397916794\n",
            "epoch 1580, loss 0.11772782355546951\n",
            "epoch 1600, loss 0.11772111058235168\n",
            "epoch 1620, loss 0.11771442741155624\n",
            "epoch 1640, loss 0.11770772188901901\n",
            "epoch 1660, loss 0.11770103126764297\n",
            "epoch 1680, loss 0.11769434809684753\n",
            "epoch 1700, loss 0.1176876574754715\n",
            "epoch 1720, loss 0.11768098175525665\n",
            "epoch 1740, loss 0.11767430603504181\n",
            "epoch 1760, loss 0.11766763031482697\n",
            "epoch 1780, loss 0.11766095459461212\n",
            "epoch 1800, loss 0.11765429377555847\n",
            "epoch 1820, loss 0.11764764040708542\n",
            "epoch 1840, loss 0.11764097958803177\n",
            "epoch 1860, loss 0.1176343560218811\n",
            "epoch 1880, loss 0.11762770265340805\n",
            "epoch 1900, loss 0.11762106418609619\n",
            "epoch 1920, loss 0.11761444061994553\n",
            "epoch 1940, loss 0.11760781705379486\n",
            "epoch 1960, loss 0.1176011934876442\n",
            "epoch 1980, loss 0.11759457737207413\n",
            "epoch 2000, loss 0.11758796870708466\n",
            "epoch 2020, loss 0.11758136749267578\n",
            "epoch 2040, loss 0.1175747662782669\n",
            "epoch 2060, loss 0.11756817996501923\n",
            "epoch 2080, loss 0.11756157875061035\n",
            "epoch 2100, loss 0.11755499243736267\n",
            "epoch 2120, loss 0.11754842102527618\n",
            "epoch 2140, loss 0.1175418570637703\n",
            "epoch 2160, loss 0.117535300552845\n",
            "epoch 2180, loss 0.11752873659133911\n",
            "epoch 2200, loss 0.11752217262983322\n",
            "epoch 2220, loss 0.11751561611890793\n",
            "epoch 2240, loss 0.11750908195972443\n",
            "epoch 2260, loss 0.11750254034996033\n",
            "epoch 2280, loss 0.11749600619077682\n",
            "epoch 2300, loss 0.11748945713043213\n",
            "epoch 2320, loss 0.11748293787240982\n",
            "epoch 2340, loss 0.11747641116380692\n",
            "epoch 2360, loss 0.1174698919057846\n",
            "epoch 2380, loss 0.1174633800983429\n",
            "epoch 2400, loss 0.11745686829090118\n",
            "epoch 2420, loss 0.11745035648345947\n",
            "epoch 2440, loss 0.11744387447834015\n",
            "epoch 2460, loss 0.11743737757205963\n",
            "epoch 2480, loss 0.11743088066577911\n",
            "epoch 2500, loss 0.1174243912100792\n",
            "epoch 2520, loss 0.11741792410612106\n",
            "epoch 2540, loss 0.11741143465042114\n",
            "epoch 2560, loss 0.11740497499704361\n",
            "epoch 2580, loss 0.11739850044250488\n",
            "epoch 2600, loss 0.11739204078912735\n",
            "epoch 2620, loss 0.11738557368516922\n",
            "epoch 2640, loss 0.11737912148237228\n",
            "epoch 2660, loss 0.11737269163131714\n",
            "epoch 2680, loss 0.1173662319779396\n",
            "epoch 2700, loss 0.11735979467630386\n",
            "epoch 2720, loss 0.11735336482524872\n",
            "epoch 2740, loss 0.11734692752361298\n",
            "epoch 2760, loss 0.11734049767255783\n",
            "epoch 2780, loss 0.11733407527208328\n",
            "epoch 2800, loss 0.11732765287160873\n",
            "epoch 2820, loss 0.11732123047113419\n",
            "epoch 2840, loss 0.11731483787298203\n",
            "epoch 2860, loss 0.11730840057134628\n",
            "epoch 2880, loss 0.11730201542377472\n",
            "epoch 2900, loss 0.11729560792446136\n",
            "epoch 2920, loss 0.1172892153263092\n",
            "epoch 2940, loss 0.11728281527757645\n",
            "epoch 2960, loss 0.11727643013000488\n",
            "epoch 2980, loss 0.11727005243301392\n",
            "epoch 3000, loss 0.11726366728544235\n",
            "epoch 3020, loss 0.11725728213787079\n",
            "epoch 3040, loss 0.11725092679262161\n",
            "epoch 3060, loss 0.11724454164505005\n",
            "epoch 3080, loss 0.11723818629980087\n",
            "epoch 3100, loss 0.1172318160533905\n",
            "epoch 3120, loss 0.11722545325756073\n",
            "epoch 3140, loss 0.11721911281347275\n",
            "epoch 3160, loss 0.11721275001764297\n",
            "epoch 3180, loss 0.11720640957355499\n",
            "epoch 3200, loss 0.11720007658004761\n",
            "epoch 3220, loss 0.11719372868537903\n",
            "epoch 3240, loss 0.11718739569187164\n",
            "epoch 3260, loss 0.11718105524778366\n",
            "epoch 3280, loss 0.11717472225427628\n",
            "epoch 3300, loss 0.11716840416193008\n",
            "epoch 3320, loss 0.1171620711684227\n",
            "epoch 3340, loss 0.11715570837259293\n",
            "epoch 3360, loss 0.11714926362037659\n",
            "epoch 3380, loss 0.11714281886816025\n",
            "epoch 3400, loss 0.11713641881942749\n",
            "epoch 3420, loss 0.11713001132011414\n",
            "epoch 3440, loss 0.11712361872196198\n",
            "epoch 3460, loss 0.11711721867322922\n",
            "epoch 3480, loss 0.11711082607507706\n",
            "epoch 3500, loss 0.1171044409275055\n",
            "epoch 3520, loss 0.11709804832935333\n",
            "epoch 3540, loss 0.11709166318178177\n",
            "epoch 3560, loss 0.1170852780342102\n",
            "epoch 3580, loss 0.11707890778779984\n",
            "epoch 3600, loss 0.11707252264022827\n",
            "epoch 3620, loss 0.1170661672949791\n",
            "epoch 3640, loss 0.11705979704856873\n",
            "epoch 3660, loss 0.11705344170331955\n",
            "epoch 3680, loss 0.11704707145690918\n",
            "epoch 3700, loss 0.1170407384634018\n",
            "epoch 3720, loss 0.11703445762395859\n",
            "epoch 3740, loss 0.11702816188335419\n",
            "epoch 3760, loss 0.11702188849449158\n",
            "epoch 3780, loss 0.11701562255620956\n",
            "epoch 3800, loss 0.11700935661792755\n",
            "epoch 3820, loss 0.11700309813022614\n",
            "epoch 3840, loss 0.11699685454368591\n",
            "epoch 3860, loss 0.11699061095714569\n",
            "epoch 3880, loss 0.11698438227176666\n",
            "epoch 3900, loss 0.11697813868522644\n",
            "epoch 3920, loss 0.11697191745042801\n",
            "epoch 3940, loss 0.11696567386388779\n",
            "epoch 3960, loss 0.11695946753025055\n",
            "epoch 3980, loss 0.11695326119661331\n",
            "epoch 4000, loss 0.11694706976413727\n",
            "epoch 4020, loss 0.11694086343050003\n",
            "epoch 4040, loss 0.11693468689918518\n",
            "epoch 4060, loss 0.11692849546670914\n",
            "epoch 4080, loss 0.1169223040342331\n",
            "epoch 4100, loss 0.11691612005233765\n",
            "epoch 4120, loss 0.1169099286198616\n",
            "epoch 4140, loss 0.11690375953912735\n",
            "epoch 4160, loss 0.1168975830078125\n",
            "epoch 4180, loss 0.11689140647649765\n",
            "epoch 4200, loss 0.1168852373957634\n",
            "epoch 4220, loss 0.11687906831502914\n",
            "epoch 4240, loss 0.1168728917837143\n",
            "epoch 4260, loss 0.11686673760414124\n",
            "epoch 4280, loss 0.11686056852340698\n",
            "epoch 4300, loss 0.11685442924499512\n",
            "epoch 4320, loss 0.11684827506542206\n",
            "epoch 4340, loss 0.1168421283364296\n",
            "epoch 4360, loss 0.11683595925569534\n",
            "epoch 4380, loss 0.11682981997728348\n",
            "epoch 4400, loss 0.11682368069887161\n",
            "epoch 4420, loss 0.11681754142045975\n",
            "epoch 4440, loss 0.11681139469146729\n",
            "epoch 4460, loss 0.11680527031421661\n",
            "epoch 4480, loss 0.11679913848638535\n",
            "epoch 4500, loss 0.11679300665855408\n",
            "epoch 4520, loss 0.1167868822813034\n",
            "epoch 4540, loss 0.11678075045347214\n",
            "epoch 4560, loss 0.11677462607622147\n",
            "epoch 4580, loss 0.11676850914955139\n",
            "epoch 4600, loss 0.11676239222288132\n",
            "epoch 4620, loss 0.11675629019737244\n",
            "epoch 4640, loss 0.11675017327070236\n",
            "epoch 4660, loss 0.11674406379461288\n",
            "epoch 4680, loss 0.11673795431852341\n",
            "epoch 4700, loss 0.11673184484243393\n",
            "epoch 4720, loss 0.11672574281692505\n",
            "epoch 4740, loss 0.11671965569257736\n",
            "epoch 4760, loss 0.11671354621648788\n",
            "epoch 4780, loss 0.1167074590921402\n",
            "epoch 4800, loss 0.11670136451721191\n",
            "epoch 4820, loss 0.11669527739286423\n",
            "epoch 4840, loss 0.11668892204761505\n",
            "epoch 4860, loss 0.11668238043785095\n",
            "epoch 4880, loss 0.11667587608098984\n",
            "epoch 4900, loss 0.11666946113109589\n",
            "epoch 4920, loss 0.11666305363178253\n",
            "epoch 4940, loss 0.11665666103363037\n",
            "epoch 4960, loss 0.11665026098489761\n",
            "epoch 4980, loss 0.11664390563964844\n",
            "tensor([[ 7.5525e-02,  4.5195e-01,  2.5518e-02,  3.6269e-01,  1.0789e+00,\n",
            "          6.0955e-01,  7.6481e-01,  3.0795e-01,  8.7856e-01,  3.4636e-02,\n",
            "          7.0871e-01,  1.0023e+00,  2.5950e-01,  5.6108e-02,  2.1244e-02,\n",
            "          6.2519e-02],\n",
            "        [ 6.4844e-02,  4.7381e-01,  3.2646e-02,  3.7428e-01,  1.1055e+00,\n",
            "          6.2090e-01,  7.6504e-01,  3.2448e-01,  8.8668e-01,  3.5100e-02,\n",
            "          7.3547e-01,  1.0141e+00,  2.8566e-01,  7.2041e-02,  2.9208e-02,\n",
            "          7.1342e-02],\n",
            "        [ 1.1468e-01,  3.5186e-01,  2.1690e-02,  3.4160e-01,  9.6105e-01,\n",
            "          5.5408e-01,  7.3772e-01,  2.3754e-01,  8.1955e-01,  9.6162e-03,\n",
            "          5.8400e-01,  9.1593e-01,  1.3085e-01,  3.2127e-02, -4.3667e-03,\n",
            "          5.7308e-02],\n",
            "        [ 1.1402e-01,  3.5495e-01,  1.8744e-02,  3.3900e-01,  9.6420e-01,\n",
            "          5.5560e-01,  7.4098e-01,  2.3853e-01,  8.2365e-01,  1.2919e-02,\n",
            "          5.8794e-01,  9.2119e-01,  1.3602e-01,  2.7252e-02, -4.3771e-03,\n",
            "          5.3730e-02],\n",
            "        [ 1.0842e-01,  3.4169e-01,  2.2666e-02,  3.4389e-01,  9.4833e-01,\n",
            "          5.3730e-01,  7.2693e-01,  2.1853e-01,  8.1185e-01,  7.8992e-03,\n",
            "          5.6836e-01,  8.8900e-01,  1.2252e-01,  2.4017e-02,  5.1861e-04,\n",
            "          5.8503e-02],\n",
            "        [ 1.1399e-01,  3.5939e-01,  1.5472e-02,  3.3595e-01,  9.6899e-01,\n",
            "          5.5911e-01,  7.4567e-01,  2.4171e-01,  8.2892e-01,  1.6658e-02,\n",
            "          5.9390e-01,  9.2984e-01,  1.4249e-01,  2.2916e-02, -4.9312e-03,\n",
            "          4.9753e-02],\n",
            "        [ 8.5763e-02,  4.2544e-01,  2.5161e-02,  3.5781e-01,  1.0478e+00,\n",
            "          5.9488e-01,  7.5710e-01,  2.8953e-01,  8.6244e-01,  2.7469e-02,\n",
            "          6.7566e-01,  9.7882e-01,  2.2517e-01,  5.0945e-02,  1.4645e-02,\n",
            "          6.1941e-02],\n",
            "        [ 1.1458e-01,  3.5330e-01,  2.0526e-02,  3.4054e-01,  9.6258e-01,\n",
            "          5.5508e-01,  7.3925e-01,  2.3840e-01,  8.2133e-01,  1.0936e-02,\n",
            "          5.8591e-01,  9.1863e-01,  1.3306e-01,  3.0442e-02, -4.4913e-03,\n",
            "          5.5894e-02],\n",
            "        [ 1.1317e-01,  3.5603e-01,  2.2369e-02,  3.4297e-01,  9.6607e-01,\n",
            "          5.5666e-01,  7.3859e-01,  2.4094e-01,  8.2164e-01,  1.0189e-02,\n",
            "          5.8925e-01,  9.1945e-01,  1.3590e-01,  3.4253e-02, -3.3157e-03,\n",
            "          5.8158e-02],\n",
            "        [ 1.0708e-01,  3.3339e-01,  2.7355e-02,  3.4856e-01,  9.3900e-01,\n",
            "          5.2885e-01,  7.1815e-01,  2.1003e-01,  8.0296e-01,  2.4103e-03,\n",
            "          5.5679e-01,  8.7129e-01,  1.1184e-01,  2.8176e-02,  2.3434e-03,\n",
            "          6.4203e-02],\n",
            "        [ 1.0565e-01,  3.4287e-01,  1.8955e-02,  3.4103e-01,  9.4883e-01,\n",
            "          5.3441e-01,  7.2816e-01,  2.1424e-01,  8.1514e-01,  1.1876e-02,\n",
            "          5.6907e-01,  8.8817e-01,  1.2706e-01,  1.4993e-02,  1.9519e-03,\n",
            "          5.3998e-02],\n",
            "        [ 1.1237e-01,  3.5098e-01,  1.9943e-02,  3.4048e-01,  9.5946e-01,\n",
            "          5.5016e-01,  7.3677e-01,  2.3259e-01,  8.2011e-01,  1.1391e-02,\n",
            "          5.8209e-01,  9.1159e-01,  1.3195e-01,  2.6353e-02, -2.9264e-03,\n",
            "          5.5188e-02],\n",
            "        [ 1.1279e-01,  3.5992e-01,  1.9026e-02,  3.3992e-01,  9.7014e-01,\n",
            "          5.5919e-01,  7.4276e-01,  2.4297e-01,  8.2657e-01,  1.3945e-02,\n",
            "          5.9434e-01,  9.2665e-01,  1.4199e-01,  2.9208e-02, -3.6026e-03,\n",
            "          5.4095e-02],\n",
            "        [ 1.1183e-01,  3.5635e-01,  1.5470e-02,  3.3642e-01,  9.6510e-01,\n",
            "          5.5369e-01,  7.4244e-01,  2.3548e-01,  8.2681e-01,  1.6453e-02,\n",
            "          5.8912e-01,  9.2145e-01,  1.4029e-01,  1.9671e-02, -3.3039e-03,\n",
            "          4.9754e-02],\n",
            "        [ 1.0799e-01,  3.3931e-01,  2.3974e-02,  3.4520e-01,  9.4564e-01,\n",
            "          5.3482e-01,  7.2441e-01,  2.1601e-01,  8.0932e-01,  6.3626e-03,\n",
            "          5.6502e-01,  8.8386e-01,  1.1948e-01,  2.5102e-02,  1.0657e-03,\n",
            "          6.0094e-02],\n",
            "        [ 1.0686e-01,  3.3442e-01,  2.6373e-02,  3.4769e-01,  9.4005e-01,\n",
            "          5.2936e-01,  7.1924e-01,  2.1036e-01,  8.0433e-01,  3.5114e-03,\n",
            "          5.5810e-01,  8.7304e-01,  1.1356e-01,  2.6551e-02,  2.3399e-03,\n",
            "          6.3010e-02],\n",
            "        [ 1.0460e-01,  3.3468e-01,  2.3862e-02,  3.4584e-01,  9.3970e-01,\n",
            "          5.2644e-01,  7.1950e-01,  2.0636e-01,  8.0619e-01,  6.1656e-03,\n",
            "          5.5773e-01,  8.7100e-01,  1.1625e-01,  1.9873e-02,  3.5966e-03,\n",
            "          5.9963e-02],\n",
            "        [-6.1933e-03,  6.4429e-01, -6.8138e-03,  4.5020e-01,  1.2598e+00,\n",
            "          6.5801e-01,  7.7119e-01,  3.9726e-01,  9.5679e-01,  5.6176e-02,\n",
            "          9.4043e-01,  1.1444e+00,  4.4527e-01,  7.6578e-02,  8.4913e-02,\n",
            "          1.8435e-01],\n",
            "        [ 1.0237e-01,  3.7867e-01,  2.8973e-02,  3.5411e-01,  9.9354e-01,\n",
            "          5.6849e-01,  7.3953e-01,  2.5792e-01,  8.3064e-01,  1.1288e-02,\n",
            "          6.1701e-01,  9.3251e-01,  1.6324e-01,  4.9425e-02,  4.6454e-03,\n",
            "          6.6345e-02],\n",
            "        [ 1.1111e-01,  3.5994e-01,  2.4108e-02,  3.4555e-01,  9.7090e-01,\n",
            "          5.5864e-01,  7.3821e-01,  2.4399e-01,  8.2274e-01,  9.9002e-03,\n",
            "          5.9400e-01,  9.2104e-01,  1.4043e-01,  3.7896e-02, -1.7206e-03,\n",
            "          6.0303e-02],\n",
            "        [ 1.2358e-02,  6.3598e-01, -1.2358e-01,  4.2956e-01,  1.1850e+00,\n",
            "          5.9127e-01,  7.7525e-01,  3.2303e-01,  9.6097e-01,  7.6203e-02,\n",
            "          9.2565e-01,  1.1852e+00,  3.8099e-01, -7.2610e-02,  7.4552e-02,\n",
            "          2.3608e-01],\n",
            "        [ 1.0356e-01,  3.2019e-01,  3.3387e-02,  3.5497e-01,  9.2377e-01,\n",
            "          5.1347e-01,  7.0417e-01,  1.9394e-01,  7.8978e-01, -4.8233e-03,\n",
            "          5.3793e-01,  8.4154e-01,  9.6268e-02,  3.0836e-02,  6.0412e-03,\n",
            "          7.1539e-02],\n",
            "        [ 1.0521e-01,  3.3046e-01,  2.7571e-02,  3.4918e-01,  9.3531e-01,\n",
            "          5.2391e-01,  7.1504e-01,  2.0443e-01,  8.0078e-01,  1.9831e-03,\n",
            "          5.5225e-01,  8.6344e-01,  1.0950e-01,  2.5652e-02,  3.7906e-03,\n",
            "          6.4469e-02],\n",
            "        [ 1.0582e-01,  3.3440e-01,  2.5318e-02,  3.4694e-01,  9.3973e-01,\n",
            "          5.2790e-01,  7.1921e-01,  2.0841e-01,  8.0502e-01,  4.6180e-03,\n",
            "          5.5774e-01,  8.7182e-01,  1.1459e-01,  2.3603e-02,  2.9388e-03,\n",
            "          6.1730e-02],\n",
            "        [ 1.0811e-01,  3.3972e-01,  2.3793e-02,  3.4501e-01,  9.4612e-01,\n",
            "          5.3531e-01,  7.2485e-01,  2.1654e-01,  8.0973e-01,  6.5818e-03,\n",
            "          5.6562e-01,  8.8481e-01,  1.1997e-01,  2.5041e-02,  9.4451e-04,\n",
            "          5.9873e-02],\n",
            "        [ 1.0941e-01,  3.4244e-01,  2.3139e-02,  3.4411e-01,  9.4941e-01,\n",
            "          5.3927e-01,  7.2773e-01,  2.2091e-01,  8.1205e-01,  7.4527e-03,\n",
            "          5.6967e-01,  8.9157e-01,  1.2258e-01,  2.6121e-02, -1.4266e-04,\n",
            "          5.9077e-02],\n",
            "        [ 1.1413e-01,  3.5536e-01,  1.8563e-02,  3.3880e-01,  9.6468e-01,\n",
            "          5.5610e-01,  7.4142e-01,  2.3905e-01,  8.2406e-01,  1.3139e-02,\n",
            "          5.8853e-01,  9.2214e-01,  1.3650e-01,  2.7191e-02, -4.4983e-03,\n",
            "          5.3509e-02],\n",
            "        [ 1.1167e-01,  3.6482e-01,  9.1074e-03,  3.3051e-01,  9.7419e-01,\n",
            "          5.6020e-01,  7.5139e-01,  2.4130e-01,  8.3693e-01,  2.3711e-02,\n",
            "          6.0045e-01,  9.3780e-01,  1.5276e-01,  1.1060e-02, -4.2908e-03,\n",
            "          4.2023e-02],\n",
            "        [ 1.0995e-01,  3.4524e-01,  2.1649e-02,  3.4260e-01,  9.5259e-01,\n",
            "          5.4225e-01,  7.3069e-01,  2.2395e-01,  8.1499e-01,  9.2083e-03,\n",
            "          5.7361e-01,  8.9766e-01,  1.2610e-01,  2.4976e-02, -8.1092e-04,\n",
            "          5.7266e-02],\n",
            "        [ 1.0937e-01,  3.4502e-01,  2.1212e-02,  3.4232e-01,  9.5219e-01,\n",
            "          5.4127e-01,  7.3046e-01,  2.2271e-01,  8.1513e-01,  9.6521e-03,\n",
            "          5.7313e-01,  8.9657e-01,  1.2637e-01,  2.3532e-02, -4.5085e-04,\n",
            "          5.6736e-02],\n",
            "        [ 6.2576e-02,  4.8577e-01,  9.7366e-03,  3.7599e-01,  1.1052e+00,\n",
            "          6.1299e-01,  7.6688e-01,  3.1790e-01,  8.9342e-01,  4.0628e-02,\n",
            "          7.4912e-01,  1.0318e+00,  2.8788e-01,  4.6731e-02,  3.1583e-02,\n",
            "          8.7669e-02],\n",
            "        [ 8.1629e-02,  2.6698e-01,  4.9692e-02,  3.7501e-01,  8.6022e-01,\n",
            "          4.4075e-01,  6.4779e-01,  1.1464e-01,  7.4200e-01, -2.5567e-02,\n",
            "          4.5951e-01,  7.1290e-01,  4.1501e-02,  1.9401e-02,  2.5385e-02,\n",
            "          9.1384e-02],\n",
            "        [ 8.7107e-02,  4.2154e-01,  2.5600e-02,  3.5763e-01,  1.0433e+00,\n",
            "          5.9267e-01,  7.5553e-01,  2.8692e-01,  8.5970e-01,  2.6025e-02,\n",
            "          6.7076e-01,  9.7483e-01,  2.1998e-01,  5.1025e-02,  1.3857e-02,\n",
            "          6.2456e-02],\n",
            "        [ 1.0650e-01,  3.8561e-01,  8.2891e-03,  3.3238e-01,  9.9867e-01,\n",
            "          5.7464e-01,  7.6015e-01,  2.5862e-01,  8.5058e-01,  2.9719e-02,\n",
            "          6.2719e-01,  9.6166e-01,  1.7871e-01,  1.5275e-02, -1.3023e-03,\n",
            "          4.1120e-02],\n",
            "        [ 9.9876e-02,  3.2176e-01,  2.8439e-02,  3.5116e-01,  9.2444e-01,\n",
            "          5.0961e-01,  7.0581e-01,  1.8821e-01,  7.9417e-01,  4.7971e-04,\n",
            "          5.3888e-01,  8.4043e-01,  1.0233e-01,  1.8804e-02,  7.9523e-03,\n",
            "          6.5531e-02],\n",
            "        [ 9.9280e-02,  3.9190e-01,  2.2980e-02,  3.4971e-01,  1.0082e+00,\n",
            "          5.7650e-01,  7.4890e-01,  2.6589e-01,  8.4335e-01,  1.9782e-02,\n",
            "          6.3397e-01,  9.5105e-01,  1.8230e-01,  4.1458e-02,  5.6593e-03,\n",
            "          5.9097e-02],\n",
            "        [ 1.0684e-01,  3.7163e-01,  2.3518e-02,  3.4688e-01,  9.8451e-01,\n",
            "          5.6519e-01,  7.4228e-01,  2.5197e-01,  8.3041e-01,  1.3657e-02,\n",
            "          6.0863e-01,  9.3222e-01,  1.5580e-01,  3.8896e-02,  9.1381e-04,\n",
            "          5.9645e-02],\n",
            "        [ 1.1119e-01,  3.4868e-01,  2.0414e-02,  3.4118e-01,  9.5665e-01,\n",
            "          5.4671e-01,  7.3434e-01,  2.2874e-01,  8.1820e-01,  1.0739e-02,\n",
            "          5.7862e-01,  9.0577e-01,  1.2982e-01,  2.5213e-02, -1.9604e-03,\n",
            "          5.5763e-02],\n",
            "        [ 1.0904e-01,  3.6540e-01,  2.4075e-02,  3.4644e-01,  9.7728e-01,\n",
            "          5.6167e-01,  7.3990e-01,  2.4776e-01,  8.2614e-01,  1.1461e-02,\n",
            "          6.0081e-01,  9.2599e-01,  1.4753e-01,  3.8777e-02, -4.0156e-04,\n",
            "          6.0292e-02],\n",
            "        [ 1.0163e-01,  3.3875e-01,  1.7824e-02,  3.4086e-01,  9.4326e-01,\n",
            "          5.2556e-01,  7.2377e-01,  2.0377e-01,  8.1303e-01,  1.2783e-02,\n",
            "          5.6225e-01,  8.7558e-01,  1.2521e-01,  7.4776e-03,  4.7805e-03,\n",
            "          5.2630e-02],\n",
            "        [ 1.0135e-01,  3.8644e-01,  2.3013e-02,  3.4883e-01,  1.0018e+00,\n",
            "          5.7347e-01,  7.4722e-01,  2.6212e-01,  8.3995e-01,  1.8222e-02,\n",
            "          6.2715e-01,  9.4611e-01,  1.7520e-01,  4.0577e-02,  4.3403e-03,\n",
            "          5.9108e-02],\n",
            "        [ 1.0403e-01,  3.2816e-01,  2.8043e-02,  3.4987e-01,  9.3250e-01,\n",
            "          5.2046e-01,  7.1260e-01,  2.0058e-01,  7.9887e-01,  1.3313e-03,\n",
            "          5.4879e-01,  8.5762e-01,  1.0736e-01,  2.4512e-02,  4.7566e-03,\n",
            "          6.5044e-02]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}