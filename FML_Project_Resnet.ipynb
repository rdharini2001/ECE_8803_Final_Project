{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0b6148",
   "metadata": {},
   "source": [
    "# Biomarker detection in OLIVES using pretrained Models\n",
    "\n",
    "\n",
    "### Step 1: Import data\n",
    "Consistent for all models. Only change output size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98eb93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set the size of the image according to your model needs\n",
    "imageSize = 224 # ResNet works with 224x224 pixels\n",
    "\n",
    "# Custom Dataset\n",
    "class BiomarkerDataset(Dataset):\n",
    "    def __init__(self, label_file, transform=None, num_frames=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_file (str): Path to the CSV file.\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "            num_frames (int): Number of adjacent frames to use in the input sequence (1 adjacent frame -> 3 consecutive images).\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(label_file)\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "        # Exclude indices which don't have enough adjacent images\n",
    "        self.valid_indices = self.data[(self.data.iloc[:, 1] > num_frames) & (self.data.iloc[:, 1] < (50-num_frames))].index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        # we can't use the length of the data since we have to exclude the first and last image (for num_frames=1) of each OCT scan\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Base path\n",
    "        img_base_path = '/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES/OLIVES'\n",
    "        \n",
    "        # Get the actual data index\n",
    "        index = self.valid_indices[idx]\n",
    "        \n",
    "        # Initialize\n",
    "        images = []\n",
    "        \n",
    "        # Load a sequence of consecutive images\n",
    "        for i in range(index - self.num_frames, index + self.num_frames +1):\n",
    "            img_path = img_base_path + self.data.iloc[i, 0]\n",
    "            img = Image.open(img_path).convert(\"L\") # 'L' is for grayscale; can be removed!?\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                # apply data transformations (transforms it to tensor)\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            # stack torch tensor\n",
    "            img = img.squeeze(0)  # Removes the first dimension if it's 1\n",
    "            images.append(img)\n",
    "        \n",
    "        # Stack the 3 grayscale images along the channel dimension\n",
    "        # Resulting tensor shape will be [3, H, W]\n",
    "        images = torch.stack(images, dim=0)\n",
    "        # print(images.shape) # debugging\n",
    "        \n",
    "        # Biomarker columns\n",
    "        labels = torch.tensor(self.data.iloc[index, 2:18].astype(float), dtype=torch.float32)\n",
    "        \n",
    "        # Get extra clinical data\n",
    "        clinical_data = {\n",
    "            \"Eye_ID\": self.data.iloc[index, 18],\n",
    "            \"BCVA\": self.data.iloc[index, 19],\n",
    "            \"CST\": self.data.iloc[index, 20],\n",
    "            \"Patient_ID\": self.data.iloc[index, 21],\n",
    "        }\n",
    "        \n",
    "        return images, labels, clinical_data\n",
    "    \n",
    "    \n",
    "# Define transformers\n",
    "\n",
    "# Values for normalization taken from example paper\n",
    "mean = 0.1706\n",
    "std = 0.2112\n",
    "\n",
    "# train with data augmentation\n",
    "train_transformer = transforms.Compose([   \n",
    "    # transforms.RandomCrop((0.7, 1.0)),  # RandomCrop between 70% to 100% of original size\n",
    "    # transforms.RandomPerspective(distortion_scale=0.2, p=0.5, fill=0),  # Add perspective shift\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.RandomRotation(degrees=10, fill=0),  # Rotates randomly between + and - degree and fills new pixels with black\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean, std) # we have to calculate these values for our dataset\n",
    "])\n",
    "# train without data augmentation\n",
    "test_transformer = transforms.Compose([   \n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.CenterCrop(imageSize), # shouldn't do anything\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# set up train loader (just example since cross validation uses new ones)\n",
    "train_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=train_transformer, num_frames=1)\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "\n",
    "# set up test loader (this one actually is being used)\n",
    "test_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=test_transformer, num_frames=1)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=32, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dc221",
   "metadata": {},
   "source": [
    "### Step 2: Train model\n",
    "Could be easily adapted for different models. Uses cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a687101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/5\n",
      "Train Loss: 0.0048\n",
      "Validation Loss: 0.0033\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0028\n",
      "Validation Loss: 0.0027\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022\n",
      "Validation Loss: 0.0022\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019\n",
      "Validation Loss: 0.0021\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0018\n",
      "Validation Accuracy for Fold 1: 0.4990\n",
      "Fold 2/5\n",
      "Epoch 1/5\n",
      "Train Loss: 0.0016\n",
      "Validation Loss: 0.0015\n",
      "Epoch 2/5\n",
      "Train Loss: 0.0014\n",
      "Validation Loss: 0.0014\n",
      "Epoch 3/5\n",
      "Train Loss: 0.0014\n",
      "Validation Loss: 0.0014\n",
      "Epoch 4/5\n",
      "Train Loss: 0.0012\n",
      "Validation Loss: 0.0013\n",
      "Epoch 5/5\n",
      "Train Loss: 0.0011\n",
      "Validation Loss: 0.0013\n",
      "Validation Accuracy for Fold 2: 0.6011\n",
      "Fold 3/5\n",
      "Epoch 1/5\n",
      "Train Loss: 0.0011\n",
      "Validation Loss: 0.0011\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n",
      "Validation Loss: 0.0011\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n",
      "Validation Loss: 0.0012\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0012\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0011\n",
      "Validation Accuracy for Fold 3: 0.6424\n",
      "Fold 4/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n",
      "Validation Loss: 0.0010\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n",
      "Validation Loss: 0.0009\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0010\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0011\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0008\n",
      "Validation Loss: 0.0010\n",
      "Validation Accuracy for Fold 4: 0.6494\n",
      "Fold 5/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0009\n",
      "Epoch 2/5\n",
      "Train Loss: 0.0009\n",
      "Validation Loss: 0.0010\n",
      "Epoch 3/5\n",
      "Train Loss: 0.0008\n",
      "Validation Loss: 0.0009\n",
      "Epoch 4/5\n",
      "Train Loss: 0.0008\n",
      "Validation Loss: 0.0010\n",
      "Epoch 5/5\n",
      "Train Loss: 0.0008\n",
      "Validation Loss: 0.0010\n",
      "Validation Accuracy for Fold 5: 0.6898\n",
      "\n",
      "Average Accuracy over all folds: 0.6163\n"
     ]
    }
   ],
   "source": [
    "## --- Settings ---\n",
    "num_epochs=5\n",
    "batch_size=64\n",
    "num_workers=32 # need this amount of CPUs for parallel data loading\n",
    "k_folds=5\n",
    "\n",
    "# get to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## ---- Model ----\n",
    "# Import pretrained model (choose one of them based on performance)\n",
    "# model = models.resnet50(pretrained=True)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT) # this is like pre-trained true\n",
    "# Adapt it to the given task (update final layer)\n",
    "model.fc = nn.Linear(model.fc.in_features, 16)  # Number of output classes: 16 (biomarkers)\n",
    "# shift to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# --- Train/Test Loops ---\n",
    "# Training loop\n",
    "def train_loop(model, train_loader, optimizer, loss_fn, device):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels, _ in train_loader:\n",
    "    # for images, labels, _ in tqdm(train_loader, desc=\"Training\"):\n",
    "        # shift to cuda\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track predictions and labels for metrics calculation\n",
    "        running_loss += loss.item()\n",
    "        all_preds.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# test loop\n",
    "def test_loop(model, test_loader, loss_fn, device):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "        # for images, labels, _ in tqdm(val_loader, desc=\"Validating\"):\n",
    "            # shift to cuda\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get metrics\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Sigmoid activation to get probabilities, then threshold at 0.5 for binary classification\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid and threshold at 0.5\n",
    "\n",
    "            # Store the predictions and labels for each batch\n",
    "            all_preds.append(preds.cpu().numpy())  # Store as numpy for easier processing later\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = running_loss / len(test_loader.dataset)\n",
    "\n",
    "    # Convert lists of predictions and labels into a 2D array where each row is a sample, each column is a biomarker\n",
    "    all_preds = np.concatenate(all_preds, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "\n",
    "    # Calculate F1 score for each biomarker (column) independently\n",
    "    f1_scores = []\n",
    "    for i in range(all_labels.shape[1]):  # Iterate over each biomarker\n",
    "        f1 = f1_score(all_labels[:, i], all_preds[:, i], average='binary')  # Compute F1 score for the ith biomarker\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "    # Average loss\n",
    "    val_loss = running_loss / len(test_loader.dataset)\n",
    "    return val_loss, f1_scores, all_preds, all_labels\n",
    "\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "\n",
    "# Initialize object to split dataset in kfold\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=0)\n",
    "    \n",
    "fold_metrics = []\n",
    "    \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split the training dataset into training and validation folds\n",
    "    train_fold = Subset(train_dataset, train_idx)\n",
    "    val_fold = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    # Set up Dataloaders\n",
    "    train_loader = DataLoader(train_fold, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_fold, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # Set start to infinity\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "    # for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\", unit=\"epoch\"):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss = train_loop(model, train_loader, optimizer, loss_fn, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validate the model after training using validation fold\n",
    "        val_loss, f1_scores, all_preds, all_labels = test_loop(model, val_loader, loss_fn, device)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_{fold+1}.pth\")\n",
    "\n",
    "    # Load the weights of the model with the best validationg loss\n",
    "    model.load_state_dict(torch.load(f\"best_model_fold_{fold+1}.pth\", weights_only=True))\n",
    "    \n",
    "#     # Convert lists of tensors to numpy arrays for evaluation\n",
    "#     all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "#     all_labels = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    " \n",
    "    # Get Accuracy\n",
    "    # preds = (torch.sigmoid(torch.tensor(all_preds)) > 0.5).int()  # Apply sigmoid and threshold at 0.5\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    fold_metrics.append(val_accuracy)\n",
    "    print(f\"Validation Accuracy for Fold {fold+1}: {val_accuracy:.4f}\")\n",
    "\n",
    "avg_accuracy = np.mean(fold_metrics)\n",
    "print(f\"\\nAverage Accuracy over all folds: {avg_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Save model weights to a file\n",
    "torch.save(model.state_dict(), \"TEMP_ResNet50_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa20ebd",
   "metadata": {},
   "source": [
    "Now Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10f3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0008\n",
      "F1 Score for Biomarker 1: 0.7419\n",
      "F1 Score for Biomarker 2: 0.8124\n",
      "F1 Score for Biomarker 3: 0.8308\n",
      "F1 Score for Biomarker 4: 0.7412\n",
      "F1 Score for Biomarker 5: 0.9193\n",
      "F1 Score for Biomarker 6: 0.9674\n",
      "F1 Score for Biomarker 7: 0.9897\n",
      "F1 Score for Biomarker 8: 0.9563\n",
      "F1 Score for Biomarker 9: 0.8696\n",
      "F1 Score for Biomarker 10: 0.0000\n",
      "F1 Score for Biomarker 11: 0.9777\n",
      "F1 Score for Biomarker 12: 0.9458\n",
      "F1 Score for Biomarker 13: 0.8889\n",
      "F1 Score for Biomarker 14: 0.0000\n",
      "F1 Score for Biomarker 15: 0.6667\n",
      "F1 Score for Biomarker 16: 0.4872\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a test_loader, loss_fn, and device set up:\n",
    "test_loss, f1_scores, all_preds, all_labels = test_loop(model, testloader, loss_fn, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "for i, f1 in enumerate(f1_scores):\n",
    "    print(f\"F1 Score for Biomarker {i+1}: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
