{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0b6148",
   "metadata": {},
   "source": [
    "# Biomarker detection in OLIVES using pretrained Models\n",
    "\n",
    "\n",
    "### Step 1: Import data\n",
    "Consistent for all models. Only change output size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98eb93d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set the size of the image according to your model needs\n",
    "imageSize = 224 # ResNet works with 224x224 pixels\n",
    "\n",
    "# Custom Dataset\n",
    "class BiomarkerDataset(Dataset):\n",
    "    def __init__(self, label_file, transform=None, num_frames=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_file (str): Path to the CSV file.\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "            num_frames (int): Number of adjacent frames to use in the input sequence (1 adjacent frame -> 3 consecutive images).\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(label_file)\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "        # Exclude indices which don't have enough adjacent images\n",
    "        self.valid_indices = self.data[(self.data.iloc[:, 1] > num_frames) & (self.data.iloc[:, 1] < (50-num_frames))].index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        # we can't use the length of the data since we have to exclude the first and last image (for num_frames=1) of each OCT scan\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Base path\n",
    "        img_base_path = '/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES/OLIVES'\n",
    "        \n",
    "        # Get the actual data index\n",
    "        index = self.valid_indices[idx]\n",
    "        \n",
    "        # Initialize\n",
    "        images = []\n",
    "        \n",
    "        # Load a sequence of consecutive images\n",
    "        for i in range(index - self.num_frames, index + self.num_frames +1):\n",
    "            img_path = img_base_path + self.data.iloc[i, 0]\n",
    "            img = Image.open(img_path).convert(\"L\") # 'L' is for grayscale; can be removed!?\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                # apply data transformations (transforms it to tensor)\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            # stack torch tensor\n",
    "            img = img.squeeze(0)  # Removes the first dimension if it's 1\n",
    "            images.append(img)\n",
    "        \n",
    "        # Stack the 3 grayscale images along the channel dimension\n",
    "        # Resulting tensor shape will be [3, H, W]\n",
    "        images = torch.stack(images, dim=0)\n",
    "        # print(images.shape) # debugging\n",
    "        \n",
    "        # Biomarker columns\n",
    "        labels = torch.tensor(self.data.iloc[index, 2:18].astype(float), dtype=torch.float32)\n",
    "        \n",
    "        # Get extra clinical data\n",
    "        clinical_data = {\n",
    "            \"Eye_ID\": self.data.iloc[index, 18],\n",
    "            \"BCVA\": self.data.iloc[index, 19],\n",
    "            \"CST\": self.data.iloc[index, 20],\n",
    "            \"Patient_ID\": self.data.iloc[index, 21],\n",
    "        }\n",
    "        \n",
    "        return images, labels, clinical_data\n",
    "    \n",
    "    \n",
    "# Define transformers\n",
    "\n",
    "# Values for normalization taken from example paper\n",
    "mean = 0.1706\n",
    "std = 0.2112\n",
    "\n",
    "# train with data augmentation\n",
    "train_transformer = transforms.Compose([   \n",
    "    # transforms.RandomCrop((0.7, 1.0)),  # RandomCrop between 70% to 100% of original size\n",
    "    # transforms.RandomPerspective(distortion_scale=0.2, p=0.5, fill=0),  # Add perspective shift\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.RandomRotation(degrees=10, fill=0),  # Rotates randomly between + and - degree and fills new pixels with black\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean, std) # we have to calculate these values for our dataset\n",
    "])\n",
    "# train without data augmentation\n",
    "test_transformer = transforms.Compose([   \n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.CenterCrop(imageSize), # shouldn't do anything\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# set up train loader (just example since cross validation uses new ones)\n",
    "train_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=train_transformer, num_frames=1)\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "\n",
    "# set up test loader (this one actually is being used)\n",
    "test_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=test_transformer, num_frames=1)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=32, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dc221",
   "metadata": {},
   "source": [
    "### Step 2: Train model\n",
    "Could be easily adapted for different models. Uses cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a687101b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## --- Settings ---\n",
    "num_epochs=10\n",
    "batch_size=64\n",
    "num_workers=32 # need this amount of CPUs for parallel data loading\n",
    "k_folds=5\n",
    "patience=5  # Number of epochs to wait for improvement\n",
    "\n",
    "# get to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## ---- Model ----\n",
    "# Import pretrained model (choose one of them based on performance)\n",
    "# model = models.resnet50(pretrained=True)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT) # this is like pre-trained true\n",
    "model.name = \"ResNet50\"\n",
    "# Adapt it to the given task (update final layer)\n",
    "model.fc = nn.Linear(model.fc.in_features, 16)  # Number of output classes: 16 (biomarkers)\n",
    "# shift to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function, optimizer nad Learning rate sheduler\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.9) # NOT GOOD: This set every f1 score to 0!!\n",
    "    # weight decay to reduce overfitting \n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Creates all needed folders to store the model weights if they don't exist already\n",
    "os.makedirs(\"ModelWeights_TempSaves\", exist_ok=True)\n",
    "os.makedirs(f\"TrainedModels/{model.name}\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b99731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:07<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2070, Validation F1: 0.6765\n",
      "Validation Loss: 0.2078\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1657, Validation F1: 0.7688\n",
      "Validation Loss: 0.1654\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1377, Validation F1: 0.8200\n",
      "Validation Loss: 0.1386\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1275, Validation F1: 0.8351\n",
      "Validation Loss: 0.1259\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1262, Validation F1: 0.8394\n",
      "Validation Loss: 0.1243\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1089, Validation F1: 0.8656\n",
      "Validation Loss: 0.1085\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1058, Validation F1: 0.8707\n",
      "Validation Loss: 0.1054\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0999, Validation F1: 0.8797\n",
      "Validation Loss: 0.0989\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0994, Validation F1: 0.8816\n",
      "Validation Loss: 0.0977\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0933, Validation F1: 0.8892\n",
      "Validation Loss: 0.0939\n",
      "Validation Accuracy for Fold 1: 0.5570\n",
      "Fold 2/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0647, Validation F1: 0.9295\n",
      "Validation Loss: 0.0638\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0620, Validation F1: 0.9253\n",
      "Validation Loss: 0.0611\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0646, Validation F1: 0.9251\n",
      "Validation Loss: 0.0635\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0624, Validation F1: 0.9269\n",
      "Validation Loss: 0.0631\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0641, Validation F1: 0.9248\n",
      "Validation Loss: 0.0644\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0588, Validation F1: 0.9292\n",
      "Validation Loss: 0.0622\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0599, Validation F1: 0.9287\n",
      "Validation Loss: 0.0613\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0615, Validation F1: 0.9282\n",
      "Validation Loss: 0.0601\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0624, Validation F1: 0.9240\n",
      "Validation Loss: 0.0602\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0602, Validation F1: 0.9287\n",
      "Validation Loss: 0.0594\n",
      "Validation Accuracy for Fold 2: 0.6732\n",
      "Fold 3/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0473, Validation F1: 0.9476\n",
      "Validation Loss: 0.0462\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0477, Validation F1: 0.9425\n",
      "Validation Loss: 0.0475\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0492, Validation F1: 0.9433\n",
      "Validation Loss: 0.0486\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0491, Validation F1: 0.9422\n",
      "Validation Loss: 0.0490\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0495, Validation F1: 0.9416\n",
      "Validation Loss: 0.0496\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0492, Validation F1: 0.9437\n",
      "Validation Loss: 0.0488\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0491, Validation F1: 0.9406\n",
      "Validation Loss: 0.0486\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0486, Validation F1: 0.9425\n",
      "Validation Loss: 0.0481\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0504, Validation F1: 0.9390\n",
      "Validation Loss: 0.0496\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0497, Validation F1: 0.9398\n",
      "Validation Loss: 0.0509\n",
      "Validation Accuracy for Fold 3: 0.7215\n",
      "Fold 4/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0443, Validation F1: 0.9483\n",
      "Validation Loss: 0.0437\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0418, Validation F1: 0.9535\n",
      "Validation Loss: 0.0433\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0428, Validation F1: 0.9511\n",
      "Validation Loss: 0.0434\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0436, Validation F1: 0.9482\n",
      "Validation Loss: 0.0434\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0441, Validation F1: 0.9512\n",
      "Validation Loss: 0.0449\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0438, Validation F1: 0.9513\n",
      "Validation Loss: 0.0445\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0437, Validation F1: 0.9494\n",
      "Validation Loss: 0.0432\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0443, Validation F1: 0.9509\n",
      "Validation Loss: 0.0445\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0445, Validation F1: 0.9495\n",
      "Validation Loss: 0.0436\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0432, Validation F1: 0.9508\n",
      "Validation Loss: 0.0442\n",
      "Validation Accuracy for Fold 4: 0.7502\n",
      "Fold 5/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0406, Validation F1: 0.9522\n",
      "Validation Loss: 0.0407\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0407, Validation F1: 0.9524\n",
      "Validation Loss: 0.0406\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0423, Validation F1: 0.9505\n",
      "Validation Loss: 0.0409\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0419, Validation F1: 0.9512\n",
      "Validation Loss: 0.0415\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0423, Validation F1: 0.9511\n",
      "Validation Loss: 0.0422\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0413, Validation F1: 0.9508\n",
      "Validation Loss: 0.0423\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0409, Validation F1: 0.9525\n",
      "Validation Loss: 0.0410\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0420, Validation F1: 0.9521\n",
      "Validation Loss: 0.0425\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0413, Validation F1: 0.9498\n",
      "Validation Loss: 0.0418\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:05<00:00, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0414, Validation F1: 0.9512\n",
      "Validation Loss: 0.0419\n",
      "Validation Accuracy for Fold 5: 0.7731\n",
      "\n",
      "Average Accuracy over all folds: 0.6950\n"
     ]
    }
   ],
   "source": [
    "# --- Train/Test Loops ---\n",
    "# Training loop\n",
    "def train_loop(model, train_loader, optimizer, loss_fn, device):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # for images, labels, _ in train_loader:\n",
    "    for images, labels, _ in tqdm(train_loader, desc=\"Training\"):\n",
    "        # shift to cuda\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track predictions and labels for metrics calculation\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        all_preds.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "# test loop\n",
    "def test_loop(model, test_loader, loss_fn, device):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "        # for images, labels, _ in tqdm(val_loader, desc=\"Validating\"):\n",
    "            # Store labels since they won't be altered\n",
    "            # all_labels.append(labels.numpy())\n",
    "            \n",
    "            # Shift to cuda\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get metrics\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Sigmoid activation to get probabilities, then threshold at 0.5 for binary classification\n",
    "            preds = torch.sigmoid(outputs) > 0.5 \n",
    "            # preds = (torch.sigmoid(outputs) > 0.5).int()  # Apply sigmoid and threshold at 0.5\n",
    "\n",
    "            # Store (numpy for easier processing later)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = running_loss / len(test_loader.dataset)\n",
    "\n",
    "    # Convert lists of predictions and labels into a 2D array where each row is a sample, each column is a biomarker\n",
    "    all_preds = np.concatenate(all_preds, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "    \n",
    "    # Calculate F1 score for each biomarker (column) independently\n",
    "#     f1_scores = []\n",
    "#     for i in range(all_labels.shape[1]):  # Iterate over each biomarker\n",
    "#         f1 = f1_score(all_labels[:, i], all_preds[:, i], average='binary')  # Compute F1 score for the ith biomarker\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "    # Average loss\n",
    "    val_loss = running_loss / len(test_loader.dataset)\n",
    "    # return val_loss, f1_scores, all_preds, all_labels\n",
    "    return val_loss, all_preds, all_labels\n",
    "\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "\n",
    "# Initialize object to split dataset in kfold\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=0)\n",
    "\n",
    "fold_metrics = []\n",
    "    \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split the training dataset into training and validation folds\n",
    "    train_fold = Subset(train_dataset, train_idx)\n",
    "    val_fold = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    # Set up Dataloaders\n",
    "    train_loader = DataLoader(train_fold, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_fold, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # Reset parameters\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0.0\n",
    "    counter_NoImprovement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "    # for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\", unit=\"epoch\"):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss = train_loop(model, train_loader, optimizer, loss_fn, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validate the model after training using validation fold\n",
    "        val_loss, all_preds, all_labels = test_loop(model, val_loader, loss_fn, device)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validate the model after training using validation fold\n",
    "        val_loss, all_preds, all_labels = test_loop(model, val_loader, loss_fn, device)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "#         # Early stopping logic: Check if F1 improved\n",
    "#         if val_f1 > best_val_f1:\n",
    "#             best_val_f1 = val_f1\n",
    "#             no_improvement = 0  # Reset counter\n",
    "#             torch.save(model.state_dict(), f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\")\n",
    "#         else:\n",
    "#             no_improvement += 1\n",
    "\n",
    "#         # Stop training if no improvement for 'patience' epochs\n",
    "#         if no_improvement >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "        \n",
    "        # Save the best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\")\n",
    "\n",
    "    # Load the weights of the model with the best validationg loss\n",
    "    model.load_state_dict(torch.load(f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\", weights_only=True))\n",
    "    \n",
    "#     # Convert lists of tensors to numpy arrays for evaluation\n",
    "#     all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "#     all_labels = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    " \n",
    "    # Get Accuracy\n",
    "    # preds = (torch.sigmoid(torch.tensor(all_preds)) > 0.5).int()  # Apply sigmoid and threshold at 0.5\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    fold_metrics.append(val_accuracy)\n",
    "    print(f\"Validation Accuracy for Fold {fold+1}: {val_accuracy:.4f}\")\n",
    "\n",
    "avg_accuracy = np.mean(fold_metrics)\n",
    "print(f\"\\nAverage Accuracy over all folds: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa20ebd",
   "metadata": {},
   "source": [
    "Now Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0ce68ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72        69\n",
      "           1       0.90      0.69      0.78       516\n",
      "           2       0.92      0.83      0.87        29\n",
      "           3       0.96      0.67      0.79       277\n",
      "           4       0.92      0.92      0.92      4699\n",
      "           5       0.99      0.98      0.98      2130\n",
      "           6       1.00      0.99      0.99      4068\n",
      "           7       0.98      0.95      0.96       677\n",
      "           8       0.90      0.90      0.90      2102\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.99      0.98      0.98      2285\n",
      "          11       0.96      0.94      0.95      3028\n",
      "          12       0.97      0.92      0.94       180\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       1.00      0.50      0.67        10\n",
      "          15       0.83      0.35      0.49        57\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     20143\n",
      "   macro avg       0.83      0.70      0.75     20143\n",
      "weighted avg       0.96      0.94      0.95     20143\n",
      " samples avg       0.93      0.91      0.91     20143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5. Evaluation\n",
    "# ============================\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if not batch:  # Handle empty batches\n",
    "                continue\n",
    "\n",
    "            images, labels, clinical_data = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images) # .logits\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "            y_pred.append(outputs.cpu().numpy())\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluate\n",
    "y_true, y_pred = evaluate_model(model, testloader)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = (sigmoid(y_pred) > 0.5).astype(int)\n",
    "# y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Ensure `y_true` is binary\n",
    "y_true_binary = (y_true > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "report = classification_report(y_true_binary, y_pred_binary,zero_division=0)\n",
    "report_data = classification_report(y_true_binary, y_pred_binary, output_dict=True,zero_division=0) # this is not clean to print but easier to extract\n",
    "weighted_f1 = report_data['weighted avg']['f1-score']\n",
    "samples_f1 = report_data['samples avg']['f1-score']\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a246399",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfde68d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model weights to a file\n",
    "torch.save(model.state_dict(), f\"TrainedModels/{model.name}/{model.name}_f1weighted{weighted_f1:.4f}_k{k_folds}_e{num_epochs}_weights.pth\")\n",
    "# torch.save(model.state_dict(), f\"TrainedModels/{model.name}/{model.name}_f1samples{samples_f1:.4f}_k{k_folds}_e{num_epochs}_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb867d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
