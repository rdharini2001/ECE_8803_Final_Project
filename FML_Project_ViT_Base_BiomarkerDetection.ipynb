{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880a860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.local/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8312d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES/OLIVES\n"
     ]
    }
   ],
   "source": [
    "%cd /storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES/OLIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60de347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved to: Biomarker_Clinical_Data_Images_Updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "labels_file = \"Biomarker_Clinical_Data_Images.csv\"\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# Replace spaces with underscores and remove leading slashes\n",
    "df['Path (Trial/Arm/Folder/Visit/Eye/Image Name)'] = (\n",
    "    df['Path (Trial/Arm/Folder/Visit/Eye/Image Name)']\n",
    "    .str.replace(\" \", \"_\")    # Replace spaces with underscores\n",
    "    .str.lstrip(\"/\")          # Remove leading slash\n",
    ")\n",
    "\n",
    "# Save the updated CSV file\n",
    "updated_labels_file = \"Biomarker_Clinical_Data_Images_Updated.csv\"\n",
    "df.to_csv(updated_labels_file, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved to: {updated_labels_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781df605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hice1/draghavan7/.local/lib/python3.10/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b66aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b5c81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([16]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([16, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model classifier: Sequential(\n",
      "  (0): Linear(in_features=768, out_features=16, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Loss: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Loss: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Loss: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Loss: 0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Loss: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Loss: 0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Loss: 0.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Loss: 0.0405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:10<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:11<00:00, 41.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.0385\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.26      0.39       159\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.04      0.01      0.02        70\n",
      "           3       0.91      0.83      0.87      1530\n",
      "           4       0.78      0.60      0.68       684\n",
      "           5       0.83      0.95      0.89      1278\n",
      "           6       0.00      0.00      0.00        32\n",
      "           7       0.66      0.54      0.59       558\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.85      0.88      0.87       721\n",
      "          10       0.90      0.83      0.86       987\n",
      "          11       0.92      0.41      0.57        58\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00        34\n",
      "          15       0.77      0.76      0.76       980\n",
      "\n",
      "   micro avg       0.83      0.77      0.80      7116\n",
      "   macro avg       0.47      0.38      0.41      7116\n",
      "weighted avg       0.81      0.77      0.78      7116\n",
      " samples avg       0.83      0.76      0.77      7116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, AutoImageProcessor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1. Load and Process Dataset\n",
    "# ============================\n",
    "\n",
    "# Load labels file\n",
    "labels_file = \"Biomarker_Clinical_Data_Images_Updated.csv\"\n",
    "df = pd.read_csv(labels_file)\n",
    "\n",
    "# Ensure biomarkers and clinical labels are numeric\n",
    "biomarker_columns = df.columns[3:19]\n",
    "clinical_label_columns = df.columns[19:]\n",
    "\n",
    "# Convert biomarker and clinical label columns to numeric, handling errors\n",
    "df[biomarker_columns] = df[biomarker_columns].apply(pd.to_numeric, errors='coerce')\n",
    "df[clinical_label_columns] = df[clinical_label_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill any NaN values with a default (e.g., 0 for biomarkers)\n",
    "df[biomarker_columns] = df[biomarker_columns].fillna(0)\n",
    "df[clinical_label_columns] = df[clinical_label_columns].fillna(0)\n",
    "\n",
    "# Normalize biomarkers to [0, 1] range\n",
    "df[biomarker_columns] = df[biomarker_columns] / df[biomarker_columns].max()\n",
    "\n",
    "# Validate that labels are in the range [0, 1]\n",
    "assert df[biomarker_columns].max().max() <= 1, \"Biomarkers contain values greater than 1.\"\n",
    "assert df[biomarker_columns].min().min() >= 0, \"Biomarkers contain values less than 0.\"\n",
    "\n",
    "# Split data into train/test based on unique Patient_ID\n",
    "train_patients, test_patients = train_test_split(df['Patient_ID'].unique(), test_size=0.2, random_state=42)\n",
    "train_df = df[df['Patient_ID'].isin(train_patients)]\n",
    "test_df = df[df['Patient_ID'].isin(test_patients)]\n",
    "\n",
    "# ============================\n",
    "# 2. Dataset Class\n",
    "# ============================\n",
    "\n",
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, dataframe, is_multimodal=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.is_multimodal = is_multimodal\n",
    "        self.feature_extractor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        # Use the relative path directly since the current directory is the base directory\n",
    "        relative_path = row['Path (Trial/Arm/Folder/Visit/Eye/Image Name)'].strip()\n",
    "        image_path = os.path.abspath(relative_path)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Path does not exist: {image_path}\")\n",
    "            return None\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Error reading image: {image_path}\")\n",
    "            return None\n",
    "\n",
    "        # Resize and prepare the image\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = np.stack([image] * 3, axis=-1)  # Convert to 3 channels\n",
    "        image = self.feature_extractor(images=image, return_tensors=\"pt\")['pixel_values'].squeeze(0)\n",
    "\n",
    "        # Prepare labels\n",
    "        biomarkers = torch.tensor(row.iloc[3:19].values.astype(np.float32), dtype=torch.float32)\n",
    "        if self.is_multimodal:\n",
    "            clinical_labels = torch.tensor(row.iloc[19:].values.astype(np.float32), dtype=torch.float32)\n",
    "            return image, biomarkers, clinical_labels\n",
    "        return image, biomarkers\n",
    "\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = OCTDataset(train_df, is_multimodal=False)\n",
    "test_dataset = OCTDataset(test_df, is_multimodal=False)\n",
    "\n",
    "# Remove None entries from dataset\n",
    "train_dataset = [item for item in train_dataset if item is not None]\n",
    "test_dataset = [item for item in test_dataset if item is not None]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ============================\n",
    "# 3. Vision Transformer Model\n",
    "# ============================\n",
    "\n",
    "# Load Vision Transformer with ignore_mismatched_sizes\n",
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=16,\n",
    "    ignore_mismatched_sizes=True  # Handle size mismatch for the classifier layer\n",
    ")\n",
    "\n",
    "# Replace the classifier for multi-label classification\n",
    "vit_model.classifier = nn.Sequential(\n",
    "    nn.Linear(vit_model.config.hidden_size, 16),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Initialize the new classifier's weights\n",
    "def initialize_weights(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "\n",
    "vit_model.classifier.apply(initialize_weights)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit_model = vit_model.to(device)\n",
    "\n",
    "print(f\"Updated model classifier: {vit_model.classifier}\")\n",
    "\n",
    "# ============================\n",
    "# 4. Training Loop\n",
    "# ============================\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion, epochs=30):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(loader):\n",
    "            if not batch:  # Handle empty batches\n",
    "                continue\n",
    "\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "optimizer = optim.Adam(vit_model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multi-label classification\n",
    "train_model(vit_model, train_loader, optimizer, criterion)\n",
    "\n",
    "# ============================\n",
    "# 5. Evaluation\n",
    "# ============================\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if not batch:  # Handle empty batches\n",
    "                continue\n",
    "\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "            y_pred.append(outputs.cpu().numpy())\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluate\n",
    "y_true, y_pred = evaluate_model(vit_model, test_loader)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Ensure `y_true` is binary\n",
    "y_true_binary = (y_true > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b02db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
