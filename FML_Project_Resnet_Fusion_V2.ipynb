{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0b6148",
   "metadata": {},
   "source": [
    "# Biomarker Detection in OLIVES using a Pretrained ResNet50 Model and Fusion Mechanisms for Clinical Data\n",
    "\n",
    "\n",
    "### Step 1: Import data\n",
    "Consistent for all models. Only change output size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98eb93d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the size of the image according to your model needs\n",
    "imageSize = 224 # ResNet works with 224x224 pixels\n",
    "\n",
    "# Custom Dataset\n",
    "class BiomarkerDataset(Dataset):\n",
    "    def __init__(self, label_file, transform=None, num_frames=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_file (str): Path to the CSV file.\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "            num_frames (int): Number of adjacent frames to use in the input sequence (1 adjacent frame -> 3 consecutive images).\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(label_file)\n",
    "        self.transform = transform\n",
    "        self.num_frames = num_frames\n",
    "        \n",
    "        # Normalization\n",
    "        self.bcva_mean = self.data.iloc[:, 19].mean()\n",
    "        self.bcva_std = self.data.iloc[:, 19].std()\n",
    "        self.cst_mean = self.data.iloc[:, 20].mean()\n",
    "        self.cst_std = self.data.iloc[:, 20].std()\n",
    "\n",
    "        \n",
    "        # Exclude indices which don't have enough adjacent images\n",
    "        self.valid_indices = self.data[(self.data.iloc[:, 1] > num_frames) & (self.data.iloc[:, 1] < (50-num_frames))].index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        # we can't use the length of the data since we have to exclude the first and last image (for num_frames=1) of each OCT scan\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Base path\n",
    "        img_base_path = '/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES/OLIVES'\n",
    "        \n",
    "        # Get the actual data index\n",
    "        index = self.valid_indices[idx]\n",
    "        \n",
    "        # Initialize\n",
    "        images = []\n",
    "        \n",
    "        # Load a sequence of consecutive images\n",
    "        for i in range(index - self.num_frames, index + self.num_frames +1):\n",
    "            img_path = img_base_path + self.data.iloc[i, 0]\n",
    "            img = Image.open(img_path).convert(\"L\") # 'L' is for grayscale; can be removed!?\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                # apply data transformations (transforms it to tensor)\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            # stack torch tensor\n",
    "            img = img.squeeze(0)  # Removes the first dimension if it's 1\n",
    "            images.append(img)\n",
    "        \n",
    "        # Stack the 3 grayscale images along the channel dimension\n",
    "        # Resulting tensor shape will be [3, H, W]\n",
    "        images = torch.stack(images, dim=0)\n",
    "        # print(images.shape) # debugging\n",
    "        \n",
    "        # Biomarker columns\n",
    "        labels = torch.tensor(self.data.iloc[index, 2:18].astype(float), dtype=torch.float32)\n",
    "        \n",
    "        # Get clinical data:\n",
    "        eye_id = self.data.iloc[index, 18]\n",
    "        bcva = self.data.iloc[index, 19]\n",
    "        cst = self.data.iloc[index, 20]\n",
    "        patient_id = self.data.iloc[index, 21]\n",
    "        \n",
    "        # Normalize\n",
    "        bcva = (bcva - self.bcva_mean) / self.bcva_std\n",
    "        cst = (cst - self.cst_mean) / self.cst_std\n",
    "\n",
    "        # Convert clinical data to tensor\n",
    "        clinical_data = torch.tensor([eye_id, bcva, cst, patient_id], dtype=torch.float32)\n",
    "        \n",
    "        return images, labels, clinical_data\n",
    "    \n",
    "    \n",
    "# Define transformers\n",
    "\n",
    "# Values for normalization taken from example paper\n",
    "mean = 0.1706\n",
    "std = 0.2112\n",
    "\n",
    "# train with data augmentation\n",
    "train_transformer = transforms.Compose([\n",
    "    # WORSE PERFORMANCE # transforms.RandomPerspective(distortion_scale=0.1, p=0.5, fill=0),  # Add perspective shift\n",
    "    # WORSE PERFORMANCE # transforms.RandomResizedCrop(size=imageSize, scale=(0.9, 1.0)), # RandomCrop between 70% to 100% of original size\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.RandomRotation(degrees=10, fill=0),  # Rotates randomly between + and - degree and fills new pixels with black\n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean, std) # we have to calculate these values for our dataset\n",
    "])\n",
    "# train without data augmentation\n",
    "test_transformer = transforms.Compose([   \n",
    "    transforms.Resize(imageSize), # Resize to models needs\n",
    "    transforms.CenterCrop(imageSize), # shouldn't do anything\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# set up train loader (just example since cross validation uses new ones)\n",
    "train_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=train_transformer, num_frames=1)\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "\n",
    "# set up test loader (this one actually is being used)\n",
    "test_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=test_transformer, num_frames=1)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64dc221",
   "metadata": {},
   "source": [
    "### Step 2: Train model\n",
    "First we initialize our model as well as some training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a687101b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## --- Settings ---\n",
    "num_epochs=40\n",
    "batch_size=64\n",
    "num_workers=16 # need this amount of CPUs for parallel data loading\n",
    "k_folds=5\n",
    "patience=8  # Number of epochs to wait for improvement\n",
    "\n",
    "# get to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "## ---- Fusion model ----\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_eyeID, num_patientID):\n",
    "        super(FusionModel, self).__init__()\n",
    "        \n",
    "        # Image feature extractor\n",
    "        self.image_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.image_model.BackboneOutput = self.image_model.fc.in_features # should be 2048\n",
    "        self.image_model.fc = nn.Identity() # remove final layer\n",
    "        \n",
    "        # Freeze ResNet parameters\n",
    "#         for param in self.image_model.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "        # Embedding layers for categorical data\n",
    "        # These are only categorial data. Therefore just using the numerical value doesn't fit\n",
    "        # The only difference a high patient ID f.e. should make, is that it's a new patient. Shouldn't lead to higher percentages of a biomaker\n",
    "        # Alternativ: One-Hot Encoding\n",
    "        self.patient_id_embedding = nn.Embedding(num_patientID, 16)\n",
    "        self.eye_id_embedding = nn.Embedding(num_eyeID, 16)\n",
    "        \n",
    "        # Fully connected layers for numerical clinical data (e.g., BCVA, CST)\n",
    "        self.clinical_fc = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # Combine and compress all clinical data\n",
    "        self.clinical_fusion_fc = nn.Sequential(\n",
    "            nn.Linear(16 + 16 + 32, 32),  # Combine all clinical data\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 64)\n",
    "        )\n",
    "        \n",
    "#         # Attention mechanism\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Linear(16 + 16, 32),  # Combined image and clinical features\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 2),        # Output: attention weights for image and clinical features\n",
    "#             nn.Softmax(dim=1)        # Normalize weights\n",
    "#         )\n",
    "        \n",
    "        # Final fusion layers\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(self.image_model.BackboneOutput + 64, 16),  # Combine weighted features\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(256, 16)  # 16 output biomarkers\n",
    "         )\n",
    "    \n",
    "    def forward(self, image, clinical_data):\n",
    "        # Extract features from the image using ResNet50\n",
    "        image_features = self.image_model(image)\n",
    "        \n",
    "        # Clinical Data\n",
    "        # Split clinical data into components\n",
    "        eye_id = clinical_data[:, 0].long()\n",
    "        bcva = clinical_data[:, 1].view(-1, 1).float()\n",
    "        cst = clinical_data[:, 2].view(-1, 1).float()\n",
    "        patient_id = clinical_data[:, 3].long()\n",
    "        # Embed categorical clinical data\n",
    "        eye_id_features = self.eye_id_embedding(eye_id).squeeze(1)\n",
    "        patient_id_features = self.patient_id_embedding(patient_id).squeeze(1)\n",
    "        # Process numerical clinical data\n",
    "        numerical_features = torch.cat([bcva, cst], dim=1)\n",
    "        clinical_features = self.clinical_fc(numerical_features)\n",
    "        # Combine all clinical features\n",
    "        combined_clinical_features = torch.cat([patient_id_features, eye_id_features, clinical_features], dim=1)\n",
    "        fused_clinical_features = self.clinical_fusion_fc(combined_clinical_features)\n",
    "        \n",
    "#         # Attention Mechanism\n",
    "#         # Compute attention weights\n",
    "#         combined_features = torch.cat([image_features, fused_clinical_features], dim=1)\n",
    "#         attention_weights = self.attention(combined_features)\n",
    "#         # Apply attention weights to image and clinical features\n",
    "#         image_weighted = attention_weights[:, 0].unsqueeze(1) * image_features\n",
    "#         clinical_weighted = attention_weights[:, 1].unsqueeze(1) * fused_clinical_features       \n",
    "#         # Combine weighted features\n",
    "#         fused_features = image_weighted + clinical_weighted\n",
    "        \n",
    "        fused_features = torch.cat([image_features, fused_clinical_features], dim=1)\n",
    "   \n",
    "        # Final prediction through fusion layers\n",
    "        output = self.fusion_fc(fused_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Make sure there are enough different IDs available\n",
    "num_eyeID = 100\n",
    "num_patientID = 300\n",
    "# Create the model\n",
    "model = FusionModel(num_eyeID,num_patientID).to(device)\n",
    "model.name = \"FusionModelV2_ResNet50\"\n",
    "\n",
    "# DIDN'T IMPROVE # Compute class weights\n",
    "# # We need to get some information on the class balance fro the original dataset\n",
    "# BiomarkerLabel_df = pd.read_csv('OLIVES_Dataset_Labels/Biomarker_Clinical_Data_Images.csv')\n",
    "# BiomarkerLabel_df = BiomarkerLabel_df.fillna(0) # NaN fix\n",
    "# labels = BiomarkerLabel_df.columns[2:18] # Extract label columns names (biomarkers)\n",
    "# df_labels = BiomarkerLabel_df[labels]\n",
    "# # Compute class weights\n",
    "# class_counts = df_labels.sum(axis=0).astype(int)\n",
    "# # num_classes = len(class_counts)\n",
    "# total_samples = len(df_labels)\n",
    "# class_weights = total_samples / class_counts\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float32)          \n",
    "                                \n",
    "# Loss function, optimizer nad Learning rate sheduler\n",
    "# loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights.to(device)) # Loss function for multi-label classification\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.9) # NOT GOOD: This set every f1 score to 0!!\n",
    "    # weight decay to reduce overfitting \n",
    "# Scheduler (have to be used at different positions in the loop)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "schedulerBatch = CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=2000, mode='triangular')\n",
    "\n",
    "# Creates all needed folders to store the model weights if they don't exist already\n",
    "os.makedirs(\"ModelWeights_TempSaves\", exist_ok=True)\n",
    "os.makedirs(f\"TrainedModels/{model.name}\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128fd8a",
   "metadata": {},
   "source": [
    "Now we go over to the training process where we do a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b99731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:11<00:00,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2594, Validation F1: 0.5443\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1935, Validation F1: 0.7205\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 13.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1549, Validation F1: 0.7978\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1376, Validation F1: 0.8312\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1290, Validation F1: 0.8501\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1317, Validation F1: 0.8443\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1181, Validation F1: 0.8603\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1202, Validation F1: 0.8473\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1177, Validation F1: 0.8677\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1485, Validation F1: 0.8321\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1187, Validation F1: 0.8616\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1095, Validation F1: 0.8642\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1054, Validation F1: 0.8777\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1194, Validation F1: 0.8700\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1191, Validation F1: 0.8752\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1026, Validation F1: 0.8815\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1338, Validation F1: 0.8627\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1167, Validation F1: 0.8773\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1068, Validation F1: 0.8831\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1024, Validation F1: 0.8842\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1268, Validation F1: 0.8522\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1040, Validation F1: 0.8908\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1050, Validation F1: 0.8881\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0930, Validation F1: 0.8954\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0930, Validation F1: 0.9027\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0995, Validation F1: 0.9043\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0968, Validation F1: 0.9022\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1111, Validation F1: 0.8968\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0925, Validation F1: 0.9085\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1064, Validation F1: 0.9087\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1060, Validation F1: 0.9043\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1033, Validation F1: 0.9085\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1078, Validation F1: 0.9113\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1055, Validation F1: 0.9191\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1104, Validation F1: 0.9136\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1153, Validation F1: 0.9127\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1152, Validation F1: 0.9150\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1151, Validation F1: 0.9178\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1181, Validation F1: 0.9187\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1196, Validation F1: 0.9204\n",
      "Validation Accuracy for Fold 1: 0.6438\n",
      "Fold 2/5\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0106, Validation F1: 0.9922\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0081, Validation F1: 0.9930\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0075, Validation F1: 0.9929\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0063, Validation F1: 0.9949\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0062, Validation F1: 0.9951\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0069, Validation F1: 0.9943\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0084, Validation F1: 0.9914\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0089, Validation F1: 0.9901\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0094, Validation F1: 0.9914\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0160, Validation F1: 0.9829\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0167, Validation F1: 0.9813\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0236, Validation F1: 0.9724\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0303, Validation F1: 0.9661\n",
      "Early stopping triggered.\n",
      "Validation Accuracy for Fold 2: 0.8321\n",
      "Fold 3/5\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0275, Validation F1: 0.9727\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0349, Validation F1: 0.9637\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0338, Validation F1: 0.9628\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0379, Validation F1: 0.9588\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0490, Validation F1: 0.9461\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0497, Validation F1: 0.9445\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0651, Validation F1: 0.9343\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0529, Validation F1: 0.9431\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0673, Validation F1: 0.9336\n",
      "Early stopping triggered.\n",
      "Validation Accuracy for Fold 3: 0.7047\n",
      "Fold 4/5\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0485, Validation F1: 0.9481\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0597, Validation F1: 0.9329\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0612, Validation F1: 0.9305\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0707, Validation F1: 0.9266\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0795, Validation F1: 0.9113\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0603, Validation F1: 0.9352\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0601, Validation F1: 0.9367\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0654, Validation F1: 0.9365\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0520, Validation F1: 0.9468\n",
      "Early stopping triggered.\n",
      "Validation Accuracy for Fold 4: 0.7418\n",
      "Fold 5/5\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0452, Validation F1: 0.9491\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0422, Validation F1: 0.9552\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0393, Validation F1: 0.9571\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0433, Validation F1: 0.9534\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0408, Validation F1: 0.9550\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0347, Validation F1: 0.9635\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0394, Validation F1: 0.9575\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0354, Validation F1: 0.9635\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0327, Validation F1: 0.9650\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0326, Validation F1: 0.9660\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0307, Validation F1: 0.9686\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0306, Validation F1: 0.9710\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0293, Validation F1: 0.9738\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0280, Validation F1: 0.9729\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0286, Validation F1: 0.9720\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0267, Validation F1: 0.9737\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0266, Validation F1: 0.9760\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0294, Validation F1: 0.9726\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0279, Validation F1: 0.9727\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0267, Validation F1: 0.9736\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0271, Validation F1: 0.9753\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0295, Validation F1: 0.9745\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0334, Validation F1: 0.9713\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0384, Validation F1: 0.9670\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 90/90 [00:06<00:00, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0420, Validation F1: 0.9656\n",
      "Early stopping triggered.\n",
      "Validation Accuracy for Fold 5: 0.8312\n",
      "\n",
      "Average Accuracy over all folds: 0.7507\n"
     ]
    }
   ],
   "source": [
    "# --- Train/Test Loops ---\n",
    "# Training loop\n",
    "def train_loop(model, train_loader, optimizer, loss_fn, device):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # for images, labels, _ in train_loader:\n",
    "    for images, labels, clinical_data in tqdm(train_loader, desc=\"Training\"):\n",
    "        # shift to cuda\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        clinical_data = clinical_data.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, clinical_data)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        schedulerBatch.step() # CyclicLR after each batch\n",
    "        \n",
    "        # Track predictions and labels for metrics calculation\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        all_preds.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "# test loop\n",
    "def test_loop(model, test_loader, loss_fn, device):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, clinical_data in test_loader:\n",
    "        # for images, labels, _ in tqdm(val_loader, desc=\"Validating\"):\n",
    "            # Store labels since they won't be altered\n",
    "            # all_labels.append(labels.numpy())\n",
    "            \n",
    "            # Shift to cuda\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            clinical_data = clinical_data.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(images, clinical_data)\n",
    "            \n",
    "            # Get metrics\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Sigmoid activation to get probabilities, then threshold at 0.5 for binary classification\n",
    "            preds = torch.sigmoid(outputs) > 0.5 \n",
    "            # preds = (torch.sigmoid(outputs) > 0.5).int()  # Apply sigmoid and threshold at 0.5\n",
    "\n",
    "            # Store (numpy for easier processing later)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = running_loss / len(test_loader.dataset)\n",
    "\n",
    "    # Convert lists of predictions and labels into a 2D array where each row is a sample, each column is a biomarker\n",
    "    all_preds = np.concatenate(all_preds, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)  # Shape: (num_samples, num_biomarkers)\n",
    "    \n",
    "    # Calculate F1 score for each biomarker (column) independently\n",
    "#     f1_scores = []\n",
    "#     for i in range(all_labels.shape[1]):  # Iterate over each biomarker\n",
    "#         f1 = f1_score(all_labels[:, i], all_preds[:, i], average='binary')  # Compute F1 score for the ith biomarker\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "    # Average loss\n",
    "    val_loss = running_loss / len(test_loader.dataset)\n",
    "    # return val_loss, f1_scores, all_preds, all_labels\n",
    "    return val_loss, all_preds, all_labels\n",
    "\n",
    "\n",
    "# --- Cross-Validation ---\n",
    "\n",
    "# Initialize object to split dataset in kfold\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=0)\n",
    "\n",
    "fold_metrics = []\n",
    "    \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split the training dataset into training and validation folds\n",
    "    train_fold = Subset(train_dataset, train_idx)\n",
    "    val_fold = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    # Set up Dataloaders\n",
    "    train_loader = DataLoader(train_fold, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_fold, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    # Reset parameters\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0.0\n",
    "    counter_NoImprovement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "    # for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\", unit=\"epoch\"):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Train the model for one epoch\n",
    "        train_loss = train_loop(model, train_loader, optimizer, loss_fn, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        # Validate the model after training using validation fold\n",
    "        val_loss, all_preds, all_labels = test_loop(model, val_loader, loss_fn, device)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "#         scheduler.step() # ExponentialLR after each epoch\n",
    "        \n",
    "        # Early stopping logic: Check if F1 improved\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            counter_NoImprovement = 0  # Reset counter\n",
    "            torch.save(model.state_dict(), f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\")\n",
    "        else:\n",
    "            counter_NoImprovement += 1\n",
    "\n",
    "        # Stop training if no improvement for 'patience' epochs\n",
    "        if counter_NoImprovement >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            counter_NoImprovement = 0\n",
    "            break\n",
    "        \n",
    "#         # Save the best model based on validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             torch.save(model.state_dict(), f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\")\n",
    "\n",
    "    # Load the weights of the model with the best validationg loss\n",
    "    model.load_state_dict(torch.load(f\"ModelWeights_TempSaves/best_{model.name}_fold_{fold+1}.pth\", weights_only=True))\n",
    " \n",
    "    # Get Accuracy\n",
    "    # preds = (torch.sigmoid(torch.tensor(all_preds)) > 0.5).int()  # Apply sigmoid and threshold at 0.5\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    fold_metrics.append(val_accuracy)\n",
    "    print(f\"Validation Accuracy for Fold {fold+1}: {val_accuracy:.4f}\")\n",
    "\n",
    "avg_accuracy = np.mean(fold_metrics)\n",
    "print(f\"\\nAverage Accuracy over all folds: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa20ebd",
   "metadata": {},
   "source": [
    "Now Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ce68ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 112/112 [00:03<00:00, 29.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        69\n",
      "           1       0.99      0.96      0.98       516\n",
      "           2       0.97      0.97      0.97        29\n",
      "           3       0.99      0.97      0.98       277\n",
      "           4       0.99      0.99      0.99      4699\n",
      "           5       1.00      1.00      1.00      2130\n",
      "           6       1.00      1.00      1.00      4068\n",
      "           7       1.00      0.99      1.00       677\n",
      "           8       0.99      0.98      0.98      2102\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00      2285\n",
      "          11       1.00      1.00      1.00      3028\n",
      "          12       1.00      1.00      1.00       180\n",
      "          13       1.00      0.89      0.94         9\n",
      "          14       1.00      1.00      1.00        10\n",
      "          15       0.98      0.89      0.94        57\n",
      "\n",
      "   micro avg       1.00      0.99      0.99     20143\n",
      "   macro avg       0.99      0.98      0.99     20143\n",
      "weighted avg       1.00      0.99      0.99     20143\n",
      " samples avg       0.97      0.97      0.97     20143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5. Evaluation\n",
    "# ============================\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            if not batch:  # Handle empty batches\n",
    "                continue\n",
    "            images, labels, clinical_data = batch\n",
    "            images, labels, clinical_data = images.to(device), labels.to(device), clinical_data.to(device)\n",
    "            outputs = model(images,clinical_data) # .logits\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "            y_pred.append(outputs.cpu().numpy())\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluate\n",
    "y_true, y_pred = evaluate_model(model, testloader)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions\n",
    "y_pred_binary = (sigmoid(y_pred) > 0.5).astype(int)\n",
    "# y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Ensure `y_true` is binary\n",
    "y_true_binary = (y_true > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "report = classification_report(y_true_binary, y_pred_binary,zero_division=0)\n",
    "report_data = classification_report(y_true_binary, y_pred_binary, output_dict=True,zero_division=0) # this is not clean to print but easier to extract\n",
    "weighted_f1 = report_data['weighted avg']['f1-score']\n",
    "macro_f1 = report_data['macro avg']['f1-score']\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Store the predicitons in a csv file\n",
    "# get the biomarker names\n",
    "BiomarkerLabel_df = pd.read_csv('OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv')\n",
    "biomarkers = BiomarkerLabel_df.columns[2:18] # Extract label columns names (biomarkers)\n",
    "\n",
    "# Convert the predictions into a pandas DataFrame with biomarker names as columns\n",
    "df_predictions = pd.DataFrame(y_pred_binary, columns=biomarkers)\n",
    "\n",
    "# Add the \"Index\" name (as the row index)\n",
    "df_predictions.insert(0, \"Index\", df_predictions.index.to_series().apply(lambda x: f\"{x+1:04d}\"))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_predictions.to_csv(\"predictions_biomarkers.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a246399",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfde68d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model weights to a file\n",
    "torch.save(model.state_dict(), f\"TrainedModels/{model.name}/{model.name}_f1weighted{weighted_f1:.4f}_k{k_folds}_e{num_epochs}_p{patience}_weights.pth\")\n",
    "# torch.save(model.state_dict(), f\"TrainedModels/{model.name}/{model.name}_f1samples{samples_f1:.4f}_k{k_folds}_e{num_epochs}_p{patience}_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0f074",
   "metadata": {},
   "source": [
    "Include a grad cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdecc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Grad-CAM class for ResNet50\n",
    "class GradCam:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # Register hooks\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output  # Save activations\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]  # Save gradients\n",
    "\n",
    "        # Find the target layer\n",
    "        for name, module in self.model.image_model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                module.register_forward_hook(forward_hook)\n",
    "                module.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_image, clinical_data=None, target_class=None):\n",
    "        # Forward pass\n",
    "        output = self.model(input_image, clinical_data)\n",
    "\n",
    "        # Use the top predicted class if target_class is not specified\n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "\n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        class_score = output[0, target_class]\n",
    "        class_score.backward()\n",
    "\n",
    "        # Ensure gradients and activations are captured\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            raise ValueError(\"Gradients or activations were not captured properly.\")\n",
    "\n",
    "        # Compute Grad-CAM\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)  # Average gradients spatially\n",
    "        cam = torch.sum(weights * self.activations, dim=1).squeeze()  # Weighted sum of activations\n",
    "\n",
    "        # Apply ReLU and normalize to [0, 1]\n",
    "        cam = torch.relu(cam).detach().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "        return cam\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, original_image, alpha=0.4):\n",
    "        # Resize heatmap to match the original image size\n",
    "        heatmap = cv2.resize(heatmap, (original_image.size[1], original_image.size[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)  # Convert to uint8\n",
    "\n",
    "        # Create heatmap image\n",
    "        heatmap_img = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Overlay heatmap\n",
    "        overlay = cv2.addWeighted(original_image, 1 - alpha, heatmap_img, alpha, 0)\n",
    "        return overlay\n",
    "    \n",
    "# Visualization function for Grad-CAM\n",
    "def visualize_gradcam(model, gradcam, data_loader, labels, num_samples=5):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "\n",
    "    for images, _, clinical_data in data_loader:\n",
    "        images = images.to(device)\n",
    "        clinical_data = clinical_data.to(device)\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            input_image = images[i].unsqueeze(0)  # Single image\n",
    "            input_clinical = clinical_data[i].unsqueeze(0)\n",
    "            original_image = np.array(to_pil_image(input_image.squeeze(0).cpu()))  # Convert to numpy\n",
    "\n",
    "            for label_idx, label_name in enumerate(labels):\n",
    "                # Generate Grad-CAM heatmap\n",
    "                heatmap = gradcam.generate(input_image, clinical_data=input_clinical, target_class=label_idx)\n",
    "\n",
    "                # Overlay heatmap on the original image\n",
    "                overlay = gradcam.overlay_heatmap(heatmap, original_image)\n",
    "\n",
    "                # Plot\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.title(f\"Original Image: {label_name}\")\n",
    "                plt.imshow(original_image, cmap=\"gray\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.title(f\"Grad-CAM Heatmap: {label_name}\")\n",
    "                plt.imshow(overlay)\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                count += 1\n",
    "                if count >= num_samples:\n",
    "                    return\n",
    "        break\n",
    "\n",
    "# Initialize Grad-CAM with the chosen target layer\n",
    "gradcam = GradCam(model.image_model, target_layer=\"layer4\")\n",
    "\n",
    "# Visualize Grad-CAM\n",
    "visualize_gradcam(model, gradcam, data_loader, labels, num_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
