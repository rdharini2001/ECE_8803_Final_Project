{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0b6148",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess data <br>\n",
    "For consistency reasons and to be able to fuse our work together we should use the same test/training data for our different models\n",
    "\n",
    "\n",
    "a) Import <br>\n",
    "Labels are in a seperate file. Confusing folder structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405a991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# loading the label file (DataFrame)\n",
    "BiomarkerLabel_df = pd.read_csv('OLIVES_Dataset_Labels/Biomarker_Clinical_Data_Images.csv')\n",
    "\n",
    "## Extract data\n",
    "# Get image paths as your features\n",
    "df_features = BiomarkerLabel_df['Path (Trial/Arm/Folder/Visit/Eye/Image Name)']\n",
    "# Get scan number\n",
    "df_scan = BiomarkerLabel_df['Scan (n/49)']\n",
    "# Extract labels (biomarkers)\n",
    "labels = BiomarkerLabel_df.columns[2:18] \n",
    "# Get the biomarker data (target)\n",
    "df_labels = BiomarkerLabel_df[labels] \n",
    "# Get clinical data columns\n",
    "df_clinicalData = BiomarkerLabel_df[['Eye_ID', 'BCVA', 'CST', 'Patient_ID']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defea404",
   "metadata": {},
   "source": [
    "b) Train/Test split <br>\n",
    "We want an equal split. Also split the clinical data together.\n",
    "\n",
    "There are a lot of considerations that can be made here:\n",
    "- Do we want to keep sets of scans for one eye together?\n",
    "- What do we use to stratify? All biomarkers together create too many different combinations of biomarkers (one combination only exists once -> error)\n",
    "    - Use the oversampled biomarkers? (Uncommon split won't be controlled, however we don't expect good results for these anyways)\n",
    "    - Use the undersampled ones? (And let the common ones just be randomly splitted?) Create artificial data points to multiple the appearence of these \n",
    "- Do we make a difference for the two initial datasets which were put together here?\n",
    "\n",
    "<br>\n",
    "How do we manage the Inbalance?\n",
    "\n",
    "- Overrepresented Classes (Large sample sizes):\n",
    "    - [5] IR HRF (6341)\n",
    "    - [6] Fully attached vitreous face (5222)\n",
    "    - [11] Fluid (IRF) (4088)\n",
    "    - [10] DRT/ME (3003)\n",
    "    - [5] Partially attached vitreous face (2984)\n",
    "    - [8] Vitreous debris (2836)\n",
    "- Moderately Represented Classes:\n",
    "    - [7] Preretinal tissue/hemorrhage (807)\n",
    "    - [1] Disruption of EZ (604)\n",
    "    - [3] IR hemorrhages (373)\n",
    "- Rare Classes:\n",
    "    - [12] Fluid (SRF) (233)\n",
    "    - [0] Atrophy / thinning of retinal layers (166)\n",
    "- Underrepresented Classes:\n",
    "    - [15] SHRM (76)\n",
    "    - [2] DRIL (32)\n",
    "    - [9] VMT (10)\n",
    "    - [13] Disruption of RPE (10)\n",
    "    - [14] PED (serous) (10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98e097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values: \n",
      " Atrophy / thinning of retinal layers    0\n",
      "Disruption of EZ                        0\n",
      "DRIL                                    0\n",
      "IR hemorrhages                          0\n",
      "IR HRF                                  0\n",
      "Partially attached vitreous face        0\n",
      "Fully attached vitreous face            0\n",
      "Preretinal tissue/hemorrhage            0\n",
      "Vitreous debris                         0\n",
      "VMT                                     0\n",
      "DRT/ME                                  0\n",
      "Fluid (IRF)                             0\n",
      "Fluid (SRF)                             0\n",
      "Disruption of RPE                       0\n",
      "PED (serous)                            0\n",
      "SHRM                                    0\n",
      "dtype: int64 \n",
      "\n",
      "Label counts: \n",
      " Atrophy / thinning of retinal layers     166\n",
      "Disruption of EZ                         604\n",
      "DRIL                                      32\n",
      "IR hemorrhages                           373\n",
      "IR HRF                                  6341\n",
      "Partially attached vitreous face        2984\n",
      "Fully attached vitreous face            5222\n",
      "Preretinal tissue/hemorrhage             807\n",
      "Vitreous debris                         2836\n",
      "VMT                                       10\n",
      "DRT/ME                                  3003\n",
      "Fluid (IRF)                             4088\n",
      "Fluid (SRF)                              233\n",
      "Disruption of RPE                         10\n",
      "PED (serous)                              10\n",
      "SHRM                                      76\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will show how many NaN values are in each biomarker column\n",
    "print(\"NaN values: \\n\", df_labels.isna().sum(), \"\\n\")\n",
    "# Since these are not a lot we will just replace them with a 0\n",
    "df_labels = df_labels.fillna(0)\n",
    "\n",
    "# Check the distribution of biomarker labels (count occurrences)\n",
    "label_counts = df_labels.sum(axis=0).astype(int)\n",
    "print(\"Label counts: \\n\", label_counts, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1:\n",
    "# split by underrepresented classes\n",
    "\n",
    "# Combine the data we want to split\n",
    "df_combined = pd.concat([df_features, df_labels, df_clinicalData], axis=1)\n",
    "\n",
    "# set which biomarkers will be used as stratifiers\n",
    "# in this example the underrepresented classes will be used\n",
    "underrepresented_classes = ['SHRM', 'DRIL', 'VMT', 'Disruption of RPE', 'PED (serous)']\n",
    "df_labels['underrepresented'] = df_labels[underrepresented_classes].sum(axis=1) > 0\n",
    "                         \n",
    "## Split the data \n",
    "# 80/20 Train/Test split\n",
    "# We use the biomarkers data for stratisfying to make sure we get an equal distribution (doesn't quite work)\n",
    "train_data, train_data, train_labels, test_label = train_test_split(\n",
    "    df_combined, df_labels, \n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    stratify=df_labels['underrepresented']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "797a6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biomarker presence for the full eye scan (from 96 eyes):\n",
      " Atrophy / thinning of retinal layers    16\n",
      "Disruption of EZ                        46\n",
      "DRIL                                     4\n",
      "IR hemorrhages                          51\n",
      "IR HRF                                  96\n",
      "Partially attached vitreous face        67\n",
      "Fully attached vitreous face            75\n",
      "Preretinal tissue/hemorrhage            34\n",
      "Vitreous debris                         91\n",
      "VMT                                      3\n",
      "DRT/ME                                  72\n",
      "Fluid (IRF)                             93\n",
      "Fluid (SRF)                             27\n",
      "Disruption of RPE                        5\n",
      "PED (serous)                             1\n",
      "SHRM                                    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# OPTION 2:\n",
    "# split by biomarker presence for a complete eye. Keep eye set together for both visits.\n",
    "\n",
    "# Summarize biomarker presence for each Eye_ID group\n",
    "# If any scan in an eye group has a biomarker, the eye is marked as having the biomarker\n",
    "BiomarkerPresence_FullEye = BiomarkerLabel_df.groupby('Eye_ID')[labels].max()\n",
    "\n",
    "# Add a summarization column indicating overall biomarker presence for stratification\n",
    "BiomarkerPresence_FullEye['Biomarker Presence'] = BiomarkerPresence_FullEye.any(axis=1).astype(int)\n",
    "# Count Biomarker Presence for Each Label\n",
    "biomarker_counts = BiomarkerPresence_FullEye[labels].sum(axis=0).astype(int)\n",
    "print(\"Biomarker presence for the full eye scan (from 96 eyes):\\n\", biomarker_counts)\n",
    "\n",
    "# Save the summarized biomarker presence to a separate CSV\n",
    "BiomarkerPresence_FullEye.to_csv('OLIVES_Dataset_Labels/BiomarkerPresence_FullEye.csv', index=True, float_format='%.0f')\n",
    "\n",
    "# Stratified split based on the summarized biomarker presence\n",
    "train_eyes, test_eyes = train_test_split(\n",
    "    BiomarkerPresence_FullEye, \n",
    "    test_size=0.2, \n",
    "    random_state=0, \n",
    "    stratify=BiomarkerPresence_FullEye['Biomarker Presence']\n",
    ")\n",
    "\n",
    "# Filter the original DataFrame to include only rows corresponding to the split Eye_IDs\n",
    "train_data = BiomarkerLabel_df[BiomarkerLabel_df['Eye_ID'].isin(train_eyes.index)]\n",
    "test_data = BiomarkerLabel_df[BiomarkerLabel_df['Eye_ID'].isin(test_eyes.index)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c99f5",
   "metadata": {},
   "source": [
    "Only run this to store the split in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a7b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .csv files\n",
    "train_data.to_csv('OLIVES_Dataset_Labels/TEMP_BiomarkerLabel_train_data.csv', index=False)\n",
    "test_data.to_csv('OLIVES_Dataset_Labels/TEMP_BiomarkerLabel_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f37cb0",
   "metadata": {},
   "source": [
    "c) Create dataset & transformation <br>\n",
    "Different transformations for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98eb93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class BiomarkerDataset(Dataset):\n",
    "    def __init__(self, label_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_file (str): Path to the CSV file.\n",
    "            model_name (str): The name of the model to adjust the image size for.\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(label_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join('/storage/ice1/shared/d-pace_community/makerspace-datasets/MEDICAL/OLIVES', self.data.iloc[idx, 0])  # Path column + base path\n",
    "        img_path = self.data.iloc[idx, 0]  # Path column\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Determine input size based on model\n",
    "        input_size = self.model_input_sizes.get(self.model_name, self.default_size)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            # apply data transformations\n",
    "            img = self.transform(img)                    \n",
    "        \n",
    "        # Get labels (multi-label)\n",
    "        labels = torch.tensor(self.data.iloc[idx, 2:18].values, dtype=torch.float32)  # Biomarker columns\n",
    "        \n",
    "        # Get extra clinical data\n",
    "        clinical_data = {\n",
    "            \"Eye_ID\": self.data.iloc[idx, 18],\n",
    "            \"BCVA\": self.data.iloc[idx, 19],\n",
    "            \"CST\": self.data.iloc[idx, 20],\n",
    "            \"Patient_ID\": self.data.iloc[idx, 21],\n",
    "        }\n",
    "        \n",
    "        return image, labels, clinical_data\n",
    "    \n",
    "    \n",
    "# Define transformers\n",
    "\n",
    "# Values for normalization taken from paper\n",
    "mean = 0.1706\n",
    "std = 0.2112\n",
    "\n",
    "# train with data augmentation\n",
    "trainEVA02_transformer = transforms.Compose([   \n",
    "    transforms.RandomCrop((0.7, 1.0)),  # RandomCrop between 70% to 100% of original size\n",
    "    # transforms.RandomPerspective(distortion_scale=0.2, p=0.5, fill=0),  # Add perspective shift\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust color properties\n",
    "    transforms.RandomRotation(degrees=10, fill=0),  # Rotates randomly between + and - degree and fills new pixels with black\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    transforms.Resize(448), # Eva02 works with 448x448 pixels\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean, std) # we have to calculate these values for our dataset\n",
    "])\n",
    "# train without data augmentation\n",
    "testEVA02_transformer = transforms.Compose([   \n",
    "    transforms.Resize(448), # Eva02 works with 448x448 pixels\n",
    "    transforms.CenterCrop(448), # shouldn't do anything\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# set up train loader for EVA02\n",
    "trainEVA02_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=trainEVA02_transformer)\n",
    "trainloader_EVA02 = DataLoader(trainEVA02_dataset, batch_size=64, shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
    "\n",
    "# set up test loader for EVA02\n",
    "testEVA02_dataset = BiomarkerDataset(label_file='OLIVES_Dataset_Labels/BiomarkerLabel_train_data.csv', transform=testEVA02_transformer)\n",
    "testloader_EVA02 = DataLoader(testEVA02_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
